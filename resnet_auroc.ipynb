{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0776cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2daa96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # device 배정\n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f7d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2809d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cace13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train_set/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffac2a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Aneurysm</th>\n",
       "      <th>L_ICA</th>\n",
       "      <th>R_ICA</th>\n",
       "      <th>L_PCOM</th>\n",
       "      <th>R_PCOM</th>\n",
       "      <th>L_AntChor</th>\n",
       "      <th>R_AntChor</th>\n",
       "      <th>L_ACA</th>\n",
       "      <th>R_ACA</th>\n",
       "      <th>...</th>\n",
       "      <th>R_MCA</th>\n",
       "      <th>L_VA</th>\n",
       "      <th>R_VA</th>\n",
       "      <th>L_PICA</th>\n",
       "      <th>R_PICA</th>\n",
       "      <th>L_SCA</th>\n",
       "      <th>R_SCA</th>\n",
       "      <th>BA</th>\n",
       "      <th>L_PCA</th>\n",
       "      <th>R_PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2608</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Aneurysm  L_ICA  R_ICA  L_PCOM  R_PCOM  L_AntChor  R_AntChor  \\\n",
       "0      1001         0      0      0       0       0          0          0   \n",
       "1      1002         1      0      0       0       0          0          0   \n",
       "2      1004         1      0      0       0       1          0          0   \n",
       "3      1005         1      0      0       0       1          0          1   \n",
       "4      1006         0      0      0       0       0          0          0   \n",
       "...     ...       ...    ...    ...     ...     ...        ...        ...   \n",
       "1122   2607         1      0      0       0       0          0          0   \n",
       "1123   2608         1      0      0       0       0          0          0   \n",
       "1124   2609         0      0      0       0       0          0          0   \n",
       "1125   2610         0      0      0       0       0          0          0   \n",
       "1126   2611         0      0      0       0       0          0          0   \n",
       "\n",
       "      L_ACA  R_ACA  ...  R_MCA  L_VA  R_VA  L_PICA  R_PICA  L_SCA  R_SCA  BA  \\\n",
       "0         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "2         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "3         0      0  ...      1     0     0       0       0      0      1   0   \n",
       "4         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "...     ...    ...  ...    ...   ...   ...     ...     ...    ...    ...  ..   \n",
       "1122      0      0  ...      0     0     1       0       0      0      0   0   \n",
       "1123      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1124      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1125      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1126      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "\n",
       "      L_PCA  R_PCA  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "1122      0      0  \n",
       "1123      0      0  \n",
       "1124      0      0  \n",
       "1125      0      0  \n",
       "1126      0      0  \n",
       "\n",
       "[1127 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20f58909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1001,\n",
       " 1002,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1013,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1039,\n",
       " 1040,\n",
       " 1041,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1057,\n",
       " 1058,\n",
       " 1059,\n",
       " 1060,\n",
       " 1061,\n",
       " 1062,\n",
       " 1063,\n",
       " 1064,\n",
       " 1065,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1073,\n",
       " 1074,\n",
       " 1075,\n",
       " 1076,\n",
       " 1077,\n",
       " 1078,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1087,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1094,\n",
       " 1095,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1125,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " 1130,\n",
       " 1131,\n",
       " 1132,\n",
       " 1133,\n",
       " 1134,\n",
       " 1135,\n",
       " 1136,\n",
       " 1138,\n",
       " 1139,\n",
       " 1140,\n",
       " 1142,\n",
       " 1143,\n",
       " 1144,\n",
       " 1145,\n",
       " 1146,\n",
       " 1148,\n",
       " 1149,\n",
       " 1150,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153,\n",
       " 1154,\n",
       " 1155,\n",
       " 1156,\n",
       " 1157,\n",
       " 1158,\n",
       " 1159,\n",
       " 1160,\n",
       " 1161,\n",
       " 1162,\n",
       " 1163,\n",
       " 1164,\n",
       " 1165,\n",
       " 1166,\n",
       " 1167,\n",
       " 1168,\n",
       " 1169,\n",
       " 1170,\n",
       " 1171,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1175,\n",
       " 1176,\n",
       " 1177,\n",
       " 1178,\n",
       " 1179,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1183,\n",
       " 1184,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1189,\n",
       " 1190,\n",
       " 1191,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1195,\n",
       " 1196,\n",
       " 1197,\n",
       " 1198,\n",
       " 1199,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1204,\n",
       " 1205,\n",
       " 1207,\n",
       " 1208,\n",
       " 1209,\n",
       " 1210,\n",
       " 1211,\n",
       " 1212,\n",
       " 1214,\n",
       " 1215,\n",
       " 1216,\n",
       " 1217,\n",
       " 1218,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1223,\n",
       " 1224,\n",
       " 1225,\n",
       " 1226,\n",
       " 1227,\n",
       " 1228,\n",
       " 1229,\n",
       " 1230,\n",
       " 1231,\n",
       " 1232,\n",
       " 1233,\n",
       " 1234,\n",
       " 1235,\n",
       " 1236,\n",
       " 1237,\n",
       " 1238,\n",
       " 1239,\n",
       " 1240,\n",
       " 1242,\n",
       " 1243,\n",
       " 1244,\n",
       " 1245,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1250,\n",
       " 1251,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1257,\n",
       " 1258,\n",
       " 1259,\n",
       " 1260,\n",
       " 1261,\n",
       " 1262,\n",
       " 1263,\n",
       " 1264,\n",
       " 1265,\n",
       " 1266,\n",
       " 1267,\n",
       " 1268,\n",
       " 1269,\n",
       " 1270,\n",
       " 1271,\n",
       " 1272,\n",
       " 1273,\n",
       " 1274,\n",
       " 1275,\n",
       " 1276,\n",
       " 1278,\n",
       " 1279,\n",
       " 1280,\n",
       " 1281,\n",
       " 1282,\n",
       " 1283,\n",
       " 1284,\n",
       " 1285,\n",
       " 1286,\n",
       " 1287,\n",
       " 1288,\n",
       " 1289,\n",
       " 1290,\n",
       " 1291,\n",
       " 1292,\n",
       " 1293,\n",
       " 1294,\n",
       " 1295,\n",
       " 1296,\n",
       " 1297,\n",
       " 1299,\n",
       " 1300,\n",
       " 1301,\n",
       " 1302,\n",
       " 1303,\n",
       " 1304,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1308,\n",
       " 1309,\n",
       " 1310,\n",
       " 1311,\n",
       " 1312,\n",
       " 1313,\n",
       " 1314,\n",
       " 1315,\n",
       " 1316,\n",
       " 1317,\n",
       " 1318,\n",
       " 1319,\n",
       " 1320,\n",
       " 1321,\n",
       " 1323,\n",
       " 1324,\n",
       " 1325,\n",
       " 1326,\n",
       " 1327,\n",
       " 1328,\n",
       " 1329,\n",
       " 1330,\n",
       " 1331,\n",
       " 1332,\n",
       " 1333,\n",
       " 1334,\n",
       " 1335,\n",
       " 1336,\n",
       " 1337,\n",
       " 1338,\n",
       " 1339,\n",
       " 1340,\n",
       " 1341,\n",
       " 1342,\n",
       " 1343,\n",
       " 1344,\n",
       " 1345,\n",
       " 1346,\n",
       " 1347,\n",
       " 1348,\n",
       " 1349,\n",
       " 1350,\n",
       " 1351,\n",
       " 1352,\n",
       " 1353,\n",
       " 1354,\n",
       " 1355,\n",
       " 1356,\n",
       " 1357,\n",
       " 1358,\n",
       " 1359,\n",
       " 1360,\n",
       " 1361,\n",
       " 1362,\n",
       " 1363,\n",
       " 1364,\n",
       " 1365,\n",
       " 1366,\n",
       " 1367,\n",
       " 1368,\n",
       " 1370,\n",
       " 1371,\n",
       " 1372,\n",
       " 1373,\n",
       " 1374,\n",
       " 1375,\n",
       " 1376,\n",
       " 1377,\n",
       " 1378,\n",
       " 1379,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1383,\n",
       " 1384,\n",
       " 1385,\n",
       " 1386,\n",
       " 1387,\n",
       " 1388,\n",
       " 1389,\n",
       " 1390,\n",
       " 1391,\n",
       " 1392,\n",
       " 1393,\n",
       " 1394,\n",
       " 1395,\n",
       " 1396,\n",
       " 1398,\n",
       " 1399,\n",
       " 1400,\n",
       " 1401,\n",
       " 1402,\n",
       " 1403,\n",
       " 1404,\n",
       " 1405,\n",
       " 1407,\n",
       " 1408,\n",
       " 1409,\n",
       " 1410,\n",
       " 1411,\n",
       " 1412,\n",
       " 1413,\n",
       " 1414,\n",
       " 1415,\n",
       " 1416,\n",
       " 1417,\n",
       " 1418,\n",
       " 1419,\n",
       " 1420,\n",
       " 1421,\n",
       " 1422,\n",
       " 1423,\n",
       " 1424,\n",
       " 1425,\n",
       " 1426,\n",
       " 1427,\n",
       " 1428,\n",
       " 1429,\n",
       " 1430,\n",
       " 1431,\n",
       " 1432,\n",
       " 1433,\n",
       " 1434,\n",
       " 1435,\n",
       " 1436,\n",
       " 1437,\n",
       " 1438,\n",
       " 1439,\n",
       " 1440,\n",
       " 1441,\n",
       " 1442,\n",
       " 1443,\n",
       " 1444,\n",
       " 1445,\n",
       " 1446,\n",
       " 1447,\n",
       " 1448,\n",
       " 1449,\n",
       " 1450,\n",
       " 1451,\n",
       " 1452,\n",
       " 1453,\n",
       " 1454,\n",
       " 1455,\n",
       " 1456,\n",
       " 1457,\n",
       " 1458,\n",
       " 1459,\n",
       " 1460,\n",
       " 1461,\n",
       " 1462,\n",
       " 1463,\n",
       " 1464,\n",
       " 1465,\n",
       " 1466,\n",
       " 1467,\n",
       " 1468,\n",
       " 1469,\n",
       " 1470,\n",
       " 1471,\n",
       " 1472,\n",
       " 1473,\n",
       " 1474,\n",
       " 1475,\n",
       " 1476,\n",
       " 1477,\n",
       " 1478,\n",
       " 1479,\n",
       " 1480,\n",
       " 1481,\n",
       " 1482,\n",
       " 1483,\n",
       " 1484,\n",
       " 1485,\n",
       " 1486,\n",
       " 1487,\n",
       " 1488,\n",
       " 1489,\n",
       " 1490,\n",
       " 1491,\n",
       " 1492,\n",
       " 1493,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1497,\n",
       " 1498,\n",
       " 1499,\n",
       " 1500,\n",
       " 1501,\n",
       " 1502,\n",
       " 1503,\n",
       " 1504,\n",
       " 1505,\n",
       " 1506,\n",
       " 1507,\n",
       " 1508,\n",
       " 1509,\n",
       " 1510,\n",
       " 1511,\n",
       " 1512,\n",
       " 1513,\n",
       " 1514,\n",
       " 1515,\n",
       " 1516,\n",
       " 1517,\n",
       " 1518,\n",
       " 1519,\n",
       " 1520,\n",
       " 1521,\n",
       " 1522,\n",
       " 1523,\n",
       " 1524,\n",
       " 1525,\n",
       " 1526,\n",
       " 1527,\n",
       " 1528,\n",
       " 1529,\n",
       " 1530,\n",
       " 1531,\n",
       " 1533,\n",
       " 1534,\n",
       " 1535,\n",
       " 1536,\n",
       " 1537,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1541,\n",
       " 1542,\n",
       " 1543,\n",
       " 1544,\n",
       " 1545,\n",
       " 1546,\n",
       " 1547,\n",
       " 1548,\n",
       " 1549,\n",
       " 1550,\n",
       " 1552,\n",
       " 1553,\n",
       " 1554,\n",
       " 1555,\n",
       " 1556,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1560,\n",
       " 1561,\n",
       " 1562,\n",
       " 1564,\n",
       " 1565,\n",
       " 1566,\n",
       " 1567,\n",
       " 1568,\n",
       " 1569,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022,\n",
       " 2023,\n",
       " 2024,\n",
       " 2025,\n",
       " 2026,\n",
       " 2027,\n",
       " 2028,\n",
       " 2029,\n",
       " 2030,\n",
       " 2031,\n",
       " 2032,\n",
       " 2033,\n",
       " 2034,\n",
       " 2035,\n",
       " 2036,\n",
       " 2037,\n",
       " 2038,\n",
       " 2039,\n",
       " 2040,\n",
       " 2041,\n",
       " 2042,\n",
       " 2043,\n",
       " 2044,\n",
       " 2045,\n",
       " 2046,\n",
       " 2047,\n",
       " 2048,\n",
       " 2049,\n",
       " 2050,\n",
       " 2051,\n",
       " 2052,\n",
       " 2053,\n",
       " 2054,\n",
       " 2055,\n",
       " 2056,\n",
       " 2057,\n",
       " 2058,\n",
       " 2059,\n",
       " 2060,\n",
       " 2061,\n",
       " 2062,\n",
       " 2063,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2067,\n",
       " 2068,\n",
       " 2069,\n",
       " 2070,\n",
       " 2071,\n",
       " 2072,\n",
       " 2073,\n",
       " 2074,\n",
       " 2075,\n",
       " 2076,\n",
       " 2077,\n",
       " 2078,\n",
       " 2079,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2084,\n",
       " 2085,\n",
       " 2086,\n",
       " 2087,\n",
       " 2088,\n",
       " 2089,\n",
       " 2090,\n",
       " 2091,\n",
       " 2092,\n",
       " 2093,\n",
       " 2094,\n",
       " 2095,\n",
       " 2096,\n",
       " 2097,\n",
       " 2098,\n",
       " 2099,\n",
       " 2100,\n",
       " 2101,\n",
       " 2102,\n",
       " 2103,\n",
       " 2104,\n",
       " 2105,\n",
       " 2106,\n",
       " 2107,\n",
       " 2108,\n",
       " 2109,\n",
       " 2110,\n",
       " 2112,\n",
       " 2113,\n",
       " 2114,\n",
       " 2115,\n",
       " 2116,\n",
       " 2117,\n",
       " 2118,\n",
       " 2119,\n",
       " 2120,\n",
       " 2121,\n",
       " 2122,\n",
       " 2123,\n",
       " 2124,\n",
       " 2125,\n",
       " 2126,\n",
       " 2127,\n",
       " 2128,\n",
       " 2129,\n",
       " 2130,\n",
       " 2132,\n",
       " 2133,\n",
       " 2134,\n",
       " 2135,\n",
       " 2136,\n",
       " 2137,\n",
       " 2139,\n",
       " 2140,\n",
       " 2141,\n",
       " 2142,\n",
       " 2143,\n",
       " 2144,\n",
       " 2145,\n",
       " 2146,\n",
       " 2147,\n",
       " 2148,\n",
       " 2149,\n",
       " 2150,\n",
       " 2151,\n",
       " 2152,\n",
       " 2153,\n",
       " 2155,\n",
       " 2156,\n",
       " 2157,\n",
       " 2158,\n",
       " 2159,\n",
       " 2160,\n",
       " 2161,\n",
       " 2162,\n",
       " 2163,\n",
       " 2164,\n",
       " 2165,\n",
       " 2166,\n",
       " 2167,\n",
       " 2168,\n",
       " 2169,\n",
       " 2170,\n",
       " 2172,\n",
       " 2173,\n",
       " 2174,\n",
       " 2175,\n",
       " 2176,\n",
       " 2177,\n",
       " 2179,\n",
       " 2180,\n",
       " 2181,\n",
       " 2182,\n",
       " 2183,\n",
       " 2184,\n",
       " 2185,\n",
       " 2186,\n",
       " 2187,\n",
       " 2188,\n",
       " 2189,\n",
       " 2190,\n",
       " 2191,\n",
       " 2192,\n",
       " 2193,\n",
       " 2194,\n",
       " 2195,\n",
       " 2196,\n",
       " 2198,\n",
       " 2199,\n",
       " 2200,\n",
       " 2201,\n",
       " 2202,\n",
       " 2203,\n",
       " 2204,\n",
       " 2205,\n",
       " 2206,\n",
       " 2207,\n",
       " 2208,\n",
       " 2209,\n",
       " 2210,\n",
       " 2211,\n",
       " 2212,\n",
       " 2213,\n",
       " 2214,\n",
       " 2215,\n",
       " 2216,\n",
       " 2217,\n",
       " 2218,\n",
       " 2219,\n",
       " 2220,\n",
       " 2221,\n",
       " 2222,\n",
       " 2223,\n",
       " 2224,\n",
       " 2225,\n",
       " 2226,\n",
       " 2227,\n",
       " 2228,\n",
       " 2229,\n",
       " 2230,\n",
       " 2231,\n",
       " 2232,\n",
       " 2233,\n",
       " 2234,\n",
       " 2235,\n",
       " 2236,\n",
       " 2237,\n",
       " 2238,\n",
       " 2239,\n",
       " 2240,\n",
       " 2241,\n",
       " 2242,\n",
       " 2244,\n",
       " 2245,\n",
       " 2246,\n",
       " 2247,\n",
       " 2248,\n",
       " 2249,\n",
       " 2250,\n",
       " 2252,\n",
       " 2253,\n",
       " 2254,\n",
       " 2255,\n",
       " 2256,\n",
       " 2257,\n",
       " 2258,\n",
       " 2259,\n",
       " 2260,\n",
       " 2261,\n",
       " 2262,\n",
       " 2263,\n",
       " 2264,\n",
       " 2265,\n",
       " 2266,\n",
       " 2267,\n",
       " 2268,\n",
       " 2269,\n",
       " 2270,\n",
       " 2271,\n",
       " 2272,\n",
       " 2273,\n",
       " 2274,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2281,\n",
       " 2282,\n",
       " 2283,\n",
       " 2284,\n",
       " 2285,\n",
       " 2286,\n",
       " 2287,\n",
       " 2288,\n",
       " 2289,\n",
       " 2290,\n",
       " 2291,\n",
       " 2292,\n",
       " 2293,\n",
       " 2294,\n",
       " 2295,\n",
       " 2296,\n",
       " 2297,\n",
       " 2298,\n",
       " 2299,\n",
       " 2300,\n",
       " 2301,\n",
       " 2302,\n",
       " 2303,\n",
       " 2304,\n",
       " 2305,\n",
       " 2306,\n",
       " 2307,\n",
       " 2308,\n",
       " 2309,\n",
       " 2310,\n",
       " 2311,\n",
       " 2312,\n",
       " 2313,\n",
       " 2314,\n",
       " 2315,\n",
       " 2316,\n",
       " 2317,\n",
       " 2318,\n",
       " 2319,\n",
       " 2320,\n",
       " 2321,\n",
       " 2322,\n",
       " 2323,\n",
       " 2324,\n",
       " 2325,\n",
       " 2326,\n",
       " 2327,\n",
       " 2328,\n",
       " 2329,\n",
       " 2330,\n",
       " 2331,\n",
       " 2332,\n",
       " 2333,\n",
       " 2334,\n",
       " 2335,\n",
       " 2336,\n",
       " 2338,\n",
       " 2339,\n",
       " 2340,\n",
       " 2341,\n",
       " 2342,\n",
       " 2343,\n",
       " 2344,\n",
       " 2345,\n",
       " 2346,\n",
       " 2347,\n",
       " 2348,\n",
       " 2349,\n",
       " 2350,\n",
       " 2351,\n",
       " 2352,\n",
       " 2354,\n",
       " 2356,\n",
       " 2357,\n",
       " 2358,\n",
       " 2359,\n",
       " 2360,\n",
       " 2361,\n",
       " 2362,\n",
       " 2363,\n",
       " 2364,\n",
       " 2365,\n",
       " 2366,\n",
       " 2367,\n",
       " 2368,\n",
       " 2369,\n",
       " 2370,\n",
       " 2371,\n",
       " 2372,\n",
       " 2374,\n",
       " 2375,\n",
       " 2376,\n",
       " 2377,\n",
       " 2378,\n",
       " 2379,\n",
       " 2381,\n",
       " 2382,\n",
       " 2383,\n",
       " 2384,\n",
       " 2385,\n",
       " 2386,\n",
       " 2387,\n",
       " 2388,\n",
       " 2389,\n",
       " 2390,\n",
       " 2391,\n",
       " 2393,\n",
       " 2395,\n",
       " 2396,\n",
       " 2397,\n",
       " 2398,\n",
       " 2399,\n",
       " 2400,\n",
       " 2401,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 2405,\n",
       " 2406,\n",
       " 2408,\n",
       " 2409,\n",
       " 2410,\n",
       " 2411,\n",
       " 2412,\n",
       " 2414,\n",
       " 2415,\n",
       " 2416,\n",
       " 2417,\n",
       " 2418,\n",
       " 2419,\n",
       " 2420,\n",
       " 2421,\n",
       " 2422,\n",
       " 2423,\n",
       " 2424,\n",
       " 2425,\n",
       " 2426,\n",
       " 2427,\n",
       " 2429,\n",
       " 2430,\n",
       " 2431,\n",
       " 2432,\n",
       " 2433,\n",
       " 2434,\n",
       " 2435,\n",
       " 2436,\n",
       " 2437,\n",
       " 2438,\n",
       " 2439,\n",
       " 2440,\n",
       " 2442,\n",
       " 2443,\n",
       " 2444,\n",
       " 2445,\n",
       " 2446,\n",
       " 2447,\n",
       " 2448,\n",
       " 2449,\n",
       " 2450,\n",
       " 2451,\n",
       " 2453,\n",
       " 2454,\n",
       " 2455,\n",
       " 2456,\n",
       " 2457,\n",
       " 2458,\n",
       " 2459,\n",
       " 2460,\n",
       " 2461,\n",
       " 2462,\n",
       " 2463,\n",
       " 2464,\n",
       " 2465,\n",
       " 2466,\n",
       " 2468,\n",
       " 2469,\n",
       " 2470,\n",
       " 2471,\n",
       " 2472,\n",
       " 2473,\n",
       " 2474,\n",
       " 2475,\n",
       " 2477,\n",
       " 2478,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_number = train_csv['Index'].tolist()\n",
    "pat_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bdc83",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d920877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2 # albumentations 텐서화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c700693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, root_path, mode, transforms):\n",
    "        self.all_data = sorted(glob.glob(os.path.join(root_path, mode, '*')))\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        data_path = self.all_data[index]\n",
    "        in_data = sorted(glob.glob(os.path.join(data_path, '*')))\n",
    "        for i in range(8):\n",
    "            image = cv2.imread(in_data[i])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            #transform 적용\n",
    "            if self.transforms is not None:\n",
    "                augmentation = self.transforms(image = image)\n",
    "                image = augmentation['image']\n",
    "            \n",
    "            images.append(image)\n",
    "            \n",
    "            for i in pat_number:\n",
    "                if str(i) in data_path:\n",
    "                    patient_index=train_csv[train_csv['Index'] == i]\n",
    "                    patient_aneurysm = patient_index['Aneurysm']\n",
    "                    label = int(patient_aneurysm.values)\n",
    "        \n",
    "        return images, label       \n",
    "            \n",
    "    def __len__(self):\n",
    "        length = len(self.all_data)\n",
    "        return length\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c62e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "#     A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#     A.ChannelShuffle(),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 이미지넷 데이터셋 통계값으로 Normalize\n",
    "#     A.CoarseDropout(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 텐서타입은 안해줌\n",
    "    ToTensorV2() # Normalize를 먼저하고 tensor화를 진행해야한다.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f66208",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/dhkim/Desktop/directory/k-ium/data/'\n",
    "\n",
    "train_class = Custom_dataset(root_path=root_path, mode='train', transforms=train_transforms)\n",
    "valid_class = Custom_dataset(root_path=root_path, mode='val', transforms=test_transforms)\n",
    "test_class = Custom_dataset(root_path=root_path, mode='test', transforms=test_transforms)\n",
    "\n",
    "\n",
    "### Pytorch BatchLoader 생성 (학습에 이용할 최종 dataloader)\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "train_loader = DataLoader(train_class, batch_size=batch_size, shuffle = True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_class, batch_size=batch_size, shuffle = False, num_workers=0)\n",
    "test_loader = DataLoader(test_class, batch_size=batch_size, shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48d95bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhkim\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models # 모델 라이브러리 함수\n",
    "\n",
    "resnet_50 = models.resnet50(pretrained=False).to(device) # 선행학습 여부\n",
    "\n",
    "# finetuning\n",
    "\n",
    "\n",
    "import torch.nn as nn # 파이토치 뉴럴네트워크 layer 라이브러리\n",
    "# 입력 이미지의 채널 수를 조정하는 conv1 레이어 수정\n",
    "\n",
    "resnet_50.conv1 = nn.Conv2d(24, 64, kernel_size=7, stride=2, padding=3, bias=False).to(device) \n",
    "\n",
    "resnet_50.fc = nn.Linear(resnet_50.fc.in_features, 2).to(device) #마지막의 fc 레이어를 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5847134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          75,264\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 2]           4,098\n",
      "================================================================\n",
      "Total params: 23,577,986\n",
      "Trainable params: 23,577,986\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.94\n",
      "Estimated Total Size (MB): 381.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary # 모델 아키텍쳐 확인하는 함수\n",
    "\n",
    "summary(resnet_50, input_size = (24, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37cf52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.000005\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet_50.parameters(), lr = lr, weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ad8a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [00:58,  3.08s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 0/30 Loss : 0.643, Accuracy : 57.952%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 0/30 Loss : 1.109, Accuracy : 44.928% \n",
      ", AUROC : 0.43333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.43s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 1/30 Loss : 0.624, Accuracy : 63.129%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 1/30 Loss : 0.936, Accuracy : 44.928% \n",
      ", AUROC : 0.43333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:07,  3.57s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 2/30 Loss : 0.638, Accuracy : 60.867%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 2/30 Loss : 1.024, Accuracy : 44.955% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:08,  3.61s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 3/30 Loss : 0.645, Accuracy : 61.533%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 3/30 Loss : 0.758, Accuracy : 47.6% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:07,  3.57s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 4/30 Loss : 0.642, Accuracy : 60.514%, AUROC : 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 4/30 Loss : 0.817, Accuracy : 44.35% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:22,  4.33s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 5/30 Loss : 0.629, Accuracy : 59.781%, AUROC : 0.8571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 5/30 Loss : 0.735, Accuracy : 48.158% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.40s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 6/30 Loss : 0.635, Accuracy : 62.435%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 6/30 Loss : 0.816, Accuracy : 44.868% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:03,  3.34s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 7/30 Loss : 0.632, Accuracy : 64.395%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 7/30 Loss : 0.734, Accuracy : 49.458% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.67s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 8/30 Loss : 0.638, Accuracy : 59.243%, AUROC : 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 8/30 Loss : 0.731, Accuracy : 49.54% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.66s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 9/30 Loss : 0.635, Accuracy : 61.416%, AUROC : 0.5285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 9/30 Loss : 0.814, Accuracy : 44.727% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.65s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 10/30 Loss : 0.622, Accuracy : 64.667%, AUROC : 0.8285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 10/30 Loss : 0.842, Accuracy : 44.868% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.68s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 11/30 Loss : 0.628, Accuracy : 63.261%, AUROC : 0.8285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 11/30 Loss : 0.864, Accuracy : 44.895% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:06,  3.50s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 12/30 Loss : 0.639, Accuracy : 61.812%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 12/30 Loss : 0.878, Accuracy : 44.955% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:15,  3.97s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 13/30 Loss : 0.631, Accuracy : 65.459%, AUROC : 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 13/30 Loss : 1.008, Accuracy : 44.955% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.65s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 14/30 Loss : 0.637, Accuracy : 62.872%, AUROC : 0.7285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 14/30 Loss : 0.892, Accuracy : 44.868% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.43s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 15/30 Loss : 0.631, Accuracy : 63.17%, AUROC : 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 15/30 Loss : 0.937, Accuracy : 44.955% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.64s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 16/30 Loss : 0.642, Accuracy : 63.603%, AUROC : 0.8571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 16/30 Loss : 0.984, Accuracy : 44.928% \n",
      ", AUROC : 0.43333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.68s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 17/30 Loss : 0.619, Accuracy : 64.575%, AUROC : 0.8285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 17/30 Loss : 0.843, Accuracy : 44.868% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.64s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 18/30 Loss : 0.623, Accuracy : 62.58%, AUROC : 0.8571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 18/30 Loss : 0.74, Accuracy : 48.743% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.68s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 19/30 Loss : 0.632, Accuracy : 63.023%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 19/30 Loss : 0.826, Accuracy : 44.895% \n",
      ", AUROC : 0.5291666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:10,  3.70s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 20/30 Loss : 0.637, Accuracy : 61.1%, AUROC : 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 20/30 Loss : 0.84, Accuracy : 44.955% \n",
      ", AUROC : 0.4958333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:17,  4.08s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 21/30 Loss : 0.624, Accuracy : 62.467%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 21/30 Loss : 0.769, Accuracy : 45.929% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:19,  4.17s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 22/30 Loss : 0.639, Accuracy : 60.25%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 22/30 Loss : 0.745, Accuracy : 46.575% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:07,  3.54s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 23/30 Loss : 0.622, Accuracy : 62.936%, AUROC : 0.6857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 23/30 Loss : 0.829, Accuracy : 44.868% \n",
      ", AUROC : 0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.37s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 24/30 Loss : 0.63, Accuracy : 64.202%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 24/30 Loss : 0.857, Accuracy : 44.955% \n",
      ", AUROC : 0.4958333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:12,  3.84s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 25/30 Loss : 0.639, Accuracy : 60.445%, AUROC : 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 25/30 Loss : 0.812, Accuracy : 44.868% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:13,  3.87s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 26/30 Loss : 0.631, Accuracy : 59.329%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 26/30 Loss : 0.921, Accuracy : 44.928% \n",
      ", AUROC : 0.43333333333333335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:11,  3.77s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 27/30 Loss : 0.63, Accuracy : 66.986%, AUROC : 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 27/30 Loss : 0.84, Accuracy : 45.727% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:12,  3.79s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 28/30 Loss : 0.624, Accuracy : 63.634%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 28/30 Loss : 0.952, Accuracy : 44.981% \n",
      ", AUROC : 0.5291666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.38s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 29/30 Loss : 0.632, Accuracy : 62.115%, AUROC : 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21972\\3444996370.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 29/30 Loss : 0.863, Accuracy : 44.955% \n",
      ", AUROC : 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "criterion = nn.CrossEntropyLoss().to(device) # cost function\n",
    "\n",
    "train_acc_lst, train_loss_lst, test_acc_lst, test_loss_lst= [], [], [], []\n",
    "state={}\n",
    "train_auroc_lst= []\n",
    "test_auroc_lst = []\n",
    "y_pred = 0\n",
    "y_true = 0\n",
    "\n",
    "# 에포크 : training + evaluation\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "#     # ----------------- TRAINING  -------------------- \n",
    "#     # training 모델로 설정\n",
    "    resnet_50.train()\n",
    "    for i, (train_imgs, train_labels) in tqdm(enumerate(train_loader)):\n",
    "        # gpu에 할당\n",
    "#         print(len(train_img))\n",
    "#         print(len(train_label))\n",
    "        \n",
    "#         print(len(train_imgs))  # 이미지 리스트의 길이 출력\n",
    "        \n",
    "        \n",
    "        y_true = train_labels.numpy()\n",
    "        # 이미지 텐서 생성\n",
    "        train_images = torch.cat((train_imgs), dim=1)\n",
    "        train_labels = torch.tensor(train_labels)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#         print(train_images.shape)\n",
    "        \n",
    "#        24차원됨\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_img = train_images.to(device)\n",
    "        train_label = train_labels.to(device)\n",
    "        \n",
    "        output = resnet_50(train_img) # 모델에 입력\n",
    "        optimizer.zero_grad(set_to_none = True ) # 계산했던 가중치 초기화               \n",
    "        loss = criterion(output, train_label)\n",
    "        loss.backward() # 미분\n",
    "        optimizer.step() # 학습\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predictions = torch.max(output.data ,dim = 1) \n",
    "        y_pred = predictions.cpu().numpy()\n",
    "        \n",
    "        total += train_label.size(0)\n",
    "        correct += (predictions == train_label).sum().item()\n",
    "        train_acc += 100 * (correct / total)\n",
    "    \n",
    "    train_loss = round(train_loss/(i+1), 3) # 소수점 반올림\n",
    "    train_acc = round(train_acc/(i+1), 3)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    print(f'Trainset {epoch}/{epochs} Loss : {train_loss}, Accuracy : {train_acc}%, AUROC : {auroc}')\n",
    "    train_acc_lst.append(train_acc)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "  # -------------------------------------------------------------------------------------\n",
    "    test_loss = 0.0\n",
    "    corrects = 0\n",
    "    totals = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    \n",
    "#     print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    resnet_50.eval()\n",
    "    for i, (valid_img, valid_label) in enumerate(valid_loader):\n",
    "        # gpu에 할당\n",
    "        \n",
    "        y_true = valid_label.numpy()\n",
    "        valid_img = torch.cat((valid_img), dim=1)\n",
    "        valid_label = torch.tensor(valid_label)\n",
    "        \n",
    "        valid_img = valid_img.to(device)\n",
    "        valid_label = valid_label.to(device)\n",
    "        \n",
    "        outputs = resnet_50(valid_img) # 모델에 입력\n",
    "        losses = criterion(outputs, valid_label)\n",
    "        \n",
    "         # loss & acc\n",
    "        test_loss += losses.item()\n",
    "        _, predictions = torch.max(outputs.data ,dim = 1 )\n",
    "        y_pred = predictions.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        totals += valid_label.size(0)\n",
    "        corrects += (predictions == valid_label).sum().item()\n",
    "        test_acc += 100 * (corrects / totals)\n",
    "        \n",
    "    test_loss = round(test_loss/(i+1), 3) # 소수점 반올림\n",
    "    test_acc = round(test_acc/(i+1), 3)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    print(f'Validset {epoch}/{epochs} Loss : {test_loss}, Accuracy : {test_acc}% \\n, AUROC : {auroc}')\n",
    "    test_loss_lst.append(test_loss)\n",
    "    test_acc_lst.append(test_acc)\n",
    "    test_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "    if np.max(test_acc_lst) <= test_acc:\n",
    "        state['epoch'] = epoch\n",
    "        state['net'] = resnet_50.state_dict()\n",
    "\n",
    "        state['train_loss'] = train_loss\n",
    "        state['test_loss'] = test_loss\n",
    "\n",
    "        state['train_acc'] = train_acc\n",
    "        state['test_acc'] = test_acc\n",
    "# torch.save(state, '/content/drive/MyDrive/Colab Notebooks/dna/week6/resnet50_{}_{}.pth'.format(str(state['epoch']), str(state['test_acc'])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e194370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
