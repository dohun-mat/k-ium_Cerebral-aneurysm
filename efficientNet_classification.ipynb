{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553e63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a22375e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # device 배정\n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62608de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21426176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2c84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d90cd3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train_set/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e110b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Aneurysm</th>\n",
       "      <th>L_ICA</th>\n",
       "      <th>R_ICA</th>\n",
       "      <th>L_PCOM</th>\n",
       "      <th>R_PCOM</th>\n",
       "      <th>L_AntChor</th>\n",
       "      <th>R_AntChor</th>\n",
       "      <th>L_ACA</th>\n",
       "      <th>R_ACA</th>\n",
       "      <th>...</th>\n",
       "      <th>R_MCA</th>\n",
       "      <th>L_VA</th>\n",
       "      <th>R_VA</th>\n",
       "      <th>L_PICA</th>\n",
       "      <th>R_PICA</th>\n",
       "      <th>L_SCA</th>\n",
       "      <th>R_SCA</th>\n",
       "      <th>BA</th>\n",
       "      <th>L_PCA</th>\n",
       "      <th>R_PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2608</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Aneurysm  L_ICA  R_ICA  L_PCOM  R_PCOM  L_AntChor  R_AntChor  \\\n",
       "0      1001         0      0      0       0       0          0          0   \n",
       "1      1002         1      0      0       0       0          0          0   \n",
       "2      1004         1      0      0       0       1          0          0   \n",
       "3      1005         1      0      0       0       1          0          1   \n",
       "4      1006         0      0      0       0       0          0          0   \n",
       "...     ...       ...    ...    ...     ...     ...        ...        ...   \n",
       "1122   2607         1      0      0       0       0          0          0   \n",
       "1123   2608         1      0      0       0       0          0          0   \n",
       "1124   2609         0      0      0       0       0          0          0   \n",
       "1125   2610         0      0      0       0       0          0          0   \n",
       "1126   2611         0      0      0       0       0          0          0   \n",
       "\n",
       "      L_ACA  R_ACA  ...  R_MCA  L_VA  R_VA  L_PICA  R_PICA  L_SCA  R_SCA  BA  \\\n",
       "0         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "2         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "3         0      0  ...      1     0     0       0       0      0      1   0   \n",
       "4         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "...     ...    ...  ...    ...   ...   ...     ...     ...    ...    ...  ..   \n",
       "1122      0      0  ...      0     0     1       0       0      0      0   0   \n",
       "1123      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1124      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1125      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1126      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "\n",
       "      L_PCA  R_PCA  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "1122      0      0  \n",
       "1123      0      0  \n",
       "1124      0      0  \n",
       "1125      0      0  \n",
       "1126      0      0  \n",
       "\n",
       "[1127 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2fde26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1001,\n",
       " 1002,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1013,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1039,\n",
       " 1040,\n",
       " 1041,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1057,\n",
       " 1058,\n",
       " 1059,\n",
       " 1060,\n",
       " 1061,\n",
       " 1062,\n",
       " 1063,\n",
       " 1064,\n",
       " 1065,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1073,\n",
       " 1074,\n",
       " 1075,\n",
       " 1076,\n",
       " 1077,\n",
       " 1078,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1087,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1094,\n",
       " 1095,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1125,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " 1130,\n",
       " 1131,\n",
       " 1132,\n",
       " 1133,\n",
       " 1134,\n",
       " 1135,\n",
       " 1136,\n",
       " 1138,\n",
       " 1139,\n",
       " 1140,\n",
       " 1142,\n",
       " 1143,\n",
       " 1144,\n",
       " 1145,\n",
       " 1146,\n",
       " 1148,\n",
       " 1149,\n",
       " 1150,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153,\n",
       " 1154,\n",
       " 1155,\n",
       " 1156,\n",
       " 1157,\n",
       " 1158,\n",
       " 1159,\n",
       " 1160,\n",
       " 1161,\n",
       " 1162,\n",
       " 1163,\n",
       " 1164,\n",
       " 1165,\n",
       " 1166,\n",
       " 1167,\n",
       " 1168,\n",
       " 1169,\n",
       " 1170,\n",
       " 1171,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1175,\n",
       " 1176,\n",
       " 1177,\n",
       " 1178,\n",
       " 1179,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1183,\n",
       " 1184,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1189,\n",
       " 1190,\n",
       " 1191,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1195,\n",
       " 1196,\n",
       " 1197,\n",
       " 1198,\n",
       " 1199,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1204,\n",
       " 1205,\n",
       " 1207,\n",
       " 1208,\n",
       " 1209,\n",
       " 1210,\n",
       " 1211,\n",
       " 1212,\n",
       " 1214,\n",
       " 1215,\n",
       " 1216,\n",
       " 1217,\n",
       " 1218,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1223,\n",
       " 1224,\n",
       " 1225,\n",
       " 1226,\n",
       " 1227,\n",
       " 1228,\n",
       " 1229,\n",
       " 1230,\n",
       " 1231,\n",
       " 1232,\n",
       " 1233,\n",
       " 1234,\n",
       " 1235,\n",
       " 1236,\n",
       " 1237,\n",
       " 1238,\n",
       " 1239,\n",
       " 1240,\n",
       " 1242,\n",
       " 1243,\n",
       " 1244,\n",
       " 1245,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1250,\n",
       " 1251,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1257,\n",
       " 1258,\n",
       " 1259,\n",
       " 1260,\n",
       " 1261,\n",
       " 1262,\n",
       " 1263,\n",
       " 1264,\n",
       " 1265,\n",
       " 1266,\n",
       " 1267,\n",
       " 1268,\n",
       " 1269,\n",
       " 1270,\n",
       " 1271,\n",
       " 1272,\n",
       " 1273,\n",
       " 1274,\n",
       " 1275,\n",
       " 1276,\n",
       " 1278,\n",
       " 1279,\n",
       " 1280,\n",
       " 1281,\n",
       " 1282,\n",
       " 1283,\n",
       " 1284,\n",
       " 1285,\n",
       " 1286,\n",
       " 1287,\n",
       " 1288,\n",
       " 1289,\n",
       " 1290,\n",
       " 1291,\n",
       " 1292,\n",
       " 1293,\n",
       " 1294,\n",
       " 1295,\n",
       " 1296,\n",
       " 1297,\n",
       " 1299,\n",
       " 1300,\n",
       " 1301,\n",
       " 1302,\n",
       " 1303,\n",
       " 1304,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1308,\n",
       " 1309,\n",
       " 1310,\n",
       " 1311,\n",
       " 1312,\n",
       " 1313,\n",
       " 1314,\n",
       " 1315,\n",
       " 1316,\n",
       " 1317,\n",
       " 1318,\n",
       " 1319,\n",
       " 1320,\n",
       " 1321,\n",
       " 1323,\n",
       " 1324,\n",
       " 1325,\n",
       " 1326,\n",
       " 1327,\n",
       " 1328,\n",
       " 1329,\n",
       " 1330,\n",
       " 1331,\n",
       " 1332,\n",
       " 1333,\n",
       " 1334,\n",
       " 1335,\n",
       " 1336,\n",
       " 1337,\n",
       " 1338,\n",
       " 1339,\n",
       " 1340,\n",
       " 1341,\n",
       " 1342,\n",
       " 1343,\n",
       " 1344,\n",
       " 1345,\n",
       " 1346,\n",
       " 1347,\n",
       " 1348,\n",
       " 1349,\n",
       " 1350,\n",
       " 1351,\n",
       " 1352,\n",
       " 1353,\n",
       " 1354,\n",
       " 1355,\n",
       " 1356,\n",
       " 1357,\n",
       " 1358,\n",
       " 1359,\n",
       " 1360,\n",
       " 1361,\n",
       " 1362,\n",
       " 1363,\n",
       " 1364,\n",
       " 1365,\n",
       " 1366,\n",
       " 1367,\n",
       " 1368,\n",
       " 1370,\n",
       " 1371,\n",
       " 1372,\n",
       " 1373,\n",
       " 1374,\n",
       " 1375,\n",
       " 1376,\n",
       " 1377,\n",
       " 1378,\n",
       " 1379,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1383,\n",
       " 1384,\n",
       " 1385,\n",
       " 1386,\n",
       " 1387,\n",
       " 1388,\n",
       " 1389,\n",
       " 1390,\n",
       " 1391,\n",
       " 1392,\n",
       " 1393,\n",
       " 1394,\n",
       " 1395,\n",
       " 1396,\n",
       " 1398,\n",
       " 1399,\n",
       " 1400,\n",
       " 1401,\n",
       " 1402,\n",
       " 1403,\n",
       " 1404,\n",
       " 1405,\n",
       " 1407,\n",
       " 1408,\n",
       " 1409,\n",
       " 1410,\n",
       " 1411,\n",
       " 1412,\n",
       " 1413,\n",
       " 1414,\n",
       " 1415,\n",
       " 1416,\n",
       " 1417,\n",
       " 1418,\n",
       " 1419,\n",
       " 1420,\n",
       " 1421,\n",
       " 1422,\n",
       " 1423,\n",
       " 1424,\n",
       " 1425,\n",
       " 1426,\n",
       " 1427,\n",
       " 1428,\n",
       " 1429,\n",
       " 1430,\n",
       " 1431,\n",
       " 1432,\n",
       " 1433,\n",
       " 1434,\n",
       " 1435,\n",
       " 1436,\n",
       " 1437,\n",
       " 1438,\n",
       " 1439,\n",
       " 1440,\n",
       " 1441,\n",
       " 1442,\n",
       " 1443,\n",
       " 1444,\n",
       " 1445,\n",
       " 1446,\n",
       " 1447,\n",
       " 1448,\n",
       " 1449,\n",
       " 1450,\n",
       " 1451,\n",
       " 1452,\n",
       " 1453,\n",
       " 1454,\n",
       " 1455,\n",
       " 1456,\n",
       " 1457,\n",
       " 1458,\n",
       " 1459,\n",
       " 1460,\n",
       " 1461,\n",
       " 1462,\n",
       " 1463,\n",
       " 1464,\n",
       " 1465,\n",
       " 1466,\n",
       " 1467,\n",
       " 1468,\n",
       " 1469,\n",
       " 1470,\n",
       " 1471,\n",
       " 1472,\n",
       " 1473,\n",
       " 1474,\n",
       " 1475,\n",
       " 1476,\n",
       " 1477,\n",
       " 1478,\n",
       " 1479,\n",
       " 1480,\n",
       " 1481,\n",
       " 1482,\n",
       " 1483,\n",
       " 1484,\n",
       " 1485,\n",
       " 1486,\n",
       " 1487,\n",
       " 1488,\n",
       " 1489,\n",
       " 1490,\n",
       " 1491,\n",
       " 1492,\n",
       " 1493,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1497,\n",
       " 1498,\n",
       " 1499,\n",
       " 1500,\n",
       " 1501,\n",
       " 1502,\n",
       " 1503,\n",
       " 1504,\n",
       " 1505,\n",
       " 1506,\n",
       " 1507,\n",
       " 1508,\n",
       " 1509,\n",
       " 1510,\n",
       " 1511,\n",
       " 1512,\n",
       " 1513,\n",
       " 1514,\n",
       " 1515,\n",
       " 1516,\n",
       " 1517,\n",
       " 1518,\n",
       " 1519,\n",
       " 1520,\n",
       " 1521,\n",
       " 1522,\n",
       " 1523,\n",
       " 1524,\n",
       " 1525,\n",
       " 1526,\n",
       " 1527,\n",
       " 1528,\n",
       " 1529,\n",
       " 1530,\n",
       " 1531,\n",
       " 1533,\n",
       " 1534,\n",
       " 1535,\n",
       " 1536,\n",
       " 1537,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1541,\n",
       " 1542,\n",
       " 1543,\n",
       " 1544,\n",
       " 1545,\n",
       " 1546,\n",
       " 1547,\n",
       " 1548,\n",
       " 1549,\n",
       " 1550,\n",
       " 1552,\n",
       " 1553,\n",
       " 1554,\n",
       " 1555,\n",
       " 1556,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1560,\n",
       " 1561,\n",
       " 1562,\n",
       " 1564,\n",
       " 1565,\n",
       " 1566,\n",
       " 1567,\n",
       " 1568,\n",
       " 1569,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022,\n",
       " 2023,\n",
       " 2024,\n",
       " 2025,\n",
       " 2026,\n",
       " 2027,\n",
       " 2028,\n",
       " 2029,\n",
       " 2030,\n",
       " 2031,\n",
       " 2032,\n",
       " 2033,\n",
       " 2034,\n",
       " 2035,\n",
       " 2036,\n",
       " 2037,\n",
       " 2038,\n",
       " 2039,\n",
       " 2040,\n",
       " 2041,\n",
       " 2042,\n",
       " 2043,\n",
       " 2044,\n",
       " 2045,\n",
       " 2046,\n",
       " 2047,\n",
       " 2048,\n",
       " 2049,\n",
       " 2050,\n",
       " 2051,\n",
       " 2052,\n",
       " 2053,\n",
       " 2054,\n",
       " 2055,\n",
       " 2056,\n",
       " 2057,\n",
       " 2058,\n",
       " 2059,\n",
       " 2060,\n",
       " 2061,\n",
       " 2062,\n",
       " 2063,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2067,\n",
       " 2068,\n",
       " 2069,\n",
       " 2070,\n",
       " 2071,\n",
       " 2072,\n",
       " 2073,\n",
       " 2074,\n",
       " 2075,\n",
       " 2076,\n",
       " 2077,\n",
       " 2078,\n",
       " 2079,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2084,\n",
       " 2085,\n",
       " 2086,\n",
       " 2087,\n",
       " 2088,\n",
       " 2089,\n",
       " 2090,\n",
       " 2091,\n",
       " 2092,\n",
       " 2093,\n",
       " 2094,\n",
       " 2095,\n",
       " 2096,\n",
       " 2097,\n",
       " 2098,\n",
       " 2099,\n",
       " 2100,\n",
       " 2101,\n",
       " 2102,\n",
       " 2103,\n",
       " 2104,\n",
       " 2105,\n",
       " 2106,\n",
       " 2107,\n",
       " 2108,\n",
       " 2109,\n",
       " 2110,\n",
       " 2112,\n",
       " 2113,\n",
       " 2114,\n",
       " 2115,\n",
       " 2116,\n",
       " 2117,\n",
       " 2118,\n",
       " 2119,\n",
       " 2120,\n",
       " 2121,\n",
       " 2122,\n",
       " 2123,\n",
       " 2124,\n",
       " 2125,\n",
       " 2126,\n",
       " 2127,\n",
       " 2128,\n",
       " 2129,\n",
       " 2130,\n",
       " 2132,\n",
       " 2133,\n",
       " 2134,\n",
       " 2135,\n",
       " 2136,\n",
       " 2137,\n",
       " 2139,\n",
       " 2140,\n",
       " 2141,\n",
       " 2142,\n",
       " 2143,\n",
       " 2144,\n",
       " 2145,\n",
       " 2146,\n",
       " 2147,\n",
       " 2148,\n",
       " 2149,\n",
       " 2150,\n",
       " 2151,\n",
       " 2152,\n",
       " 2153,\n",
       " 2155,\n",
       " 2156,\n",
       " 2157,\n",
       " 2158,\n",
       " 2159,\n",
       " 2160,\n",
       " 2161,\n",
       " 2162,\n",
       " 2163,\n",
       " 2164,\n",
       " 2165,\n",
       " 2166,\n",
       " 2167,\n",
       " 2168,\n",
       " 2169,\n",
       " 2170,\n",
       " 2172,\n",
       " 2173,\n",
       " 2174,\n",
       " 2175,\n",
       " 2176,\n",
       " 2177,\n",
       " 2179,\n",
       " 2180,\n",
       " 2181,\n",
       " 2182,\n",
       " 2183,\n",
       " 2184,\n",
       " 2185,\n",
       " 2186,\n",
       " 2187,\n",
       " 2188,\n",
       " 2189,\n",
       " 2190,\n",
       " 2191,\n",
       " 2192,\n",
       " 2193,\n",
       " 2194,\n",
       " 2195,\n",
       " 2196,\n",
       " 2198,\n",
       " 2199,\n",
       " 2200,\n",
       " 2201,\n",
       " 2202,\n",
       " 2203,\n",
       " 2204,\n",
       " 2205,\n",
       " 2206,\n",
       " 2207,\n",
       " 2208,\n",
       " 2209,\n",
       " 2210,\n",
       " 2211,\n",
       " 2212,\n",
       " 2213,\n",
       " 2214,\n",
       " 2215,\n",
       " 2216,\n",
       " 2217,\n",
       " 2218,\n",
       " 2219,\n",
       " 2220,\n",
       " 2221,\n",
       " 2222,\n",
       " 2223,\n",
       " 2224,\n",
       " 2225,\n",
       " 2226,\n",
       " 2227,\n",
       " 2228,\n",
       " 2229,\n",
       " 2230,\n",
       " 2231,\n",
       " 2232,\n",
       " 2233,\n",
       " 2234,\n",
       " 2235,\n",
       " 2236,\n",
       " 2237,\n",
       " 2238,\n",
       " 2239,\n",
       " 2240,\n",
       " 2241,\n",
       " 2242,\n",
       " 2244,\n",
       " 2245,\n",
       " 2246,\n",
       " 2247,\n",
       " 2248,\n",
       " 2249,\n",
       " 2250,\n",
       " 2252,\n",
       " 2253,\n",
       " 2254,\n",
       " 2255,\n",
       " 2256,\n",
       " 2257,\n",
       " 2258,\n",
       " 2259,\n",
       " 2260,\n",
       " 2261,\n",
       " 2262,\n",
       " 2263,\n",
       " 2264,\n",
       " 2265,\n",
       " 2266,\n",
       " 2267,\n",
       " 2268,\n",
       " 2269,\n",
       " 2270,\n",
       " 2271,\n",
       " 2272,\n",
       " 2273,\n",
       " 2274,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2281,\n",
       " 2282,\n",
       " 2283,\n",
       " 2284,\n",
       " 2285,\n",
       " 2286,\n",
       " 2287,\n",
       " 2288,\n",
       " 2289,\n",
       " 2290,\n",
       " 2291,\n",
       " 2292,\n",
       " 2293,\n",
       " 2294,\n",
       " 2295,\n",
       " 2296,\n",
       " 2297,\n",
       " 2298,\n",
       " 2299,\n",
       " 2300,\n",
       " 2301,\n",
       " 2302,\n",
       " 2303,\n",
       " 2304,\n",
       " 2305,\n",
       " 2306,\n",
       " 2307,\n",
       " 2308,\n",
       " 2309,\n",
       " 2310,\n",
       " 2311,\n",
       " 2312,\n",
       " 2313,\n",
       " 2314,\n",
       " 2315,\n",
       " 2316,\n",
       " 2317,\n",
       " 2318,\n",
       " 2319,\n",
       " 2320,\n",
       " 2321,\n",
       " 2322,\n",
       " 2323,\n",
       " 2324,\n",
       " 2325,\n",
       " 2326,\n",
       " 2327,\n",
       " 2328,\n",
       " 2329,\n",
       " 2330,\n",
       " 2331,\n",
       " 2332,\n",
       " 2333,\n",
       " 2334,\n",
       " 2335,\n",
       " 2336,\n",
       " 2338,\n",
       " 2339,\n",
       " 2340,\n",
       " 2341,\n",
       " 2342,\n",
       " 2343,\n",
       " 2344,\n",
       " 2345,\n",
       " 2346,\n",
       " 2347,\n",
       " 2348,\n",
       " 2349,\n",
       " 2350,\n",
       " 2351,\n",
       " 2352,\n",
       " 2354,\n",
       " 2356,\n",
       " 2357,\n",
       " 2358,\n",
       " 2359,\n",
       " 2360,\n",
       " 2361,\n",
       " 2362,\n",
       " 2363,\n",
       " 2364,\n",
       " 2365,\n",
       " 2366,\n",
       " 2367,\n",
       " 2368,\n",
       " 2369,\n",
       " 2370,\n",
       " 2371,\n",
       " 2372,\n",
       " 2374,\n",
       " 2375,\n",
       " 2376,\n",
       " 2377,\n",
       " 2378,\n",
       " 2379,\n",
       " 2381,\n",
       " 2382,\n",
       " 2383,\n",
       " 2384,\n",
       " 2385,\n",
       " 2386,\n",
       " 2387,\n",
       " 2388,\n",
       " 2389,\n",
       " 2390,\n",
       " 2391,\n",
       " 2393,\n",
       " 2395,\n",
       " 2396,\n",
       " 2397,\n",
       " 2398,\n",
       " 2399,\n",
       " 2400,\n",
       " 2401,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 2405,\n",
       " 2406,\n",
       " 2408,\n",
       " 2409,\n",
       " 2410,\n",
       " 2411,\n",
       " 2412,\n",
       " 2414,\n",
       " 2415,\n",
       " 2416,\n",
       " 2417,\n",
       " 2418,\n",
       " 2419,\n",
       " 2420,\n",
       " 2421,\n",
       " 2422,\n",
       " 2423,\n",
       " 2424,\n",
       " 2425,\n",
       " 2426,\n",
       " 2427,\n",
       " 2429,\n",
       " 2430,\n",
       " 2431,\n",
       " 2432,\n",
       " 2433,\n",
       " 2434,\n",
       " 2435,\n",
       " 2436,\n",
       " 2437,\n",
       " 2438,\n",
       " 2439,\n",
       " 2440,\n",
       " 2442,\n",
       " 2443,\n",
       " 2444,\n",
       " 2445,\n",
       " 2446,\n",
       " 2447,\n",
       " 2448,\n",
       " 2449,\n",
       " 2450,\n",
       " 2451,\n",
       " 2453,\n",
       " 2454,\n",
       " 2455,\n",
       " 2456,\n",
       " 2457,\n",
       " 2458,\n",
       " 2459,\n",
       " 2460,\n",
       " 2461,\n",
       " 2462,\n",
       " 2463,\n",
       " 2464,\n",
       " 2465,\n",
       " 2466,\n",
       " 2468,\n",
       " 2469,\n",
       " 2470,\n",
       " 2471,\n",
       " 2472,\n",
       " 2473,\n",
       " 2474,\n",
       " 2475,\n",
       " 2477,\n",
       " 2478,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_number = train_csv['Index'].tolist()\n",
    "pat_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c982ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2 # albumentations 텐서화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb8df7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "#     A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#     A.ChannelShuffle(),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 이미지넷 데이터셋 통계값으로 Normalize\n",
    "#     A.CoarseDropout(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 텐서타입은 안해줌\n",
    "    ToTensorV2() # Normalize를 먼저하고 tensor화를 진행해야한다.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93be1649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, root_path, mode, transforms):\n",
    "        self.all_data = sorted(glob.glob(os.path.join(root_path, mode, '*')))\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        images = []\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "            \n",
    "        data_path = self.all_data[index]\n",
    "        in_data = sorted(glob.glob(os.path.join(data_path, '*')))\n",
    "        for i in range(8):\n",
    "            image = cv2.imread(in_data[i])\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "            #transform 적용\n",
    "            if self.transforms is not None:\n",
    "                augmentation = self.transforms(image = image)\n",
    "                image = augmentation['image']\n",
    "            \n",
    "            images.append(image)\n",
    "            \n",
    "            for i in pat_number:\n",
    "                if str(i) in data_path:\n",
    "                    patient_index=train_csv[train_csv['Index'] == i]\n",
    "                    patient_aneurysm = patient_index['Aneurysm']\n",
    "                    label = int(patient_aneurysm.values)\n",
    "        \n",
    "        return images, label       \n",
    "            \n",
    "    def __len__(self):\n",
    "        length = len(self.all_data)\n",
    "        return length\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d8cb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/dhkim/Desktop/directory/k-ium/data/'\n",
    "\n",
    "train_class = Custom_dataset(root_path=root_path, mode='train', transforms=train_transforms)\n",
    "valid_class = Custom_dataset(root_path=root_path, mode='val', transforms=test_transforms)\n",
    "test_class = Custom_dataset(root_path=root_path, mode='test', transforms=test_transforms)\n",
    "\n",
    "\n",
    "### Pytorch BatchLoader 생성 (학습에 이용할 최종 dataloader)\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "train_loader = DataLoader(train_class, batch_size=batch_size, shuffle = False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_class, batch_size=batch_size, shuffle = False, num_workers=0)\n",
    "test_loader = DataLoader(test_class, batch_size=batch_size, shuffle = False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "818a41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models # 모델 라이브러리 함수\n",
    "\n",
    "# efficientnet_b0 = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "efficientnet_b0 = EfficientNet.from_name('efficientnet-b0').to(device)\n",
    "\n",
    "# finetuning\n",
    "\n",
    "\n",
    "import torch.nn as nn # 파이토치 뉴럴네트워크 layer 라이브러리\n",
    "# 입력 이미지의 채널 수를 조정하는 conv1 레이어 수정\n",
    "\n",
    "efficientnet_b0._conv_stem = nn.Conv2d(24, 32, kernel_size=3, stride=2, padding=1, bias=False).to(device) \n",
    "\n",
    "efficientnet_b0._fc = nn.Linear(efficientnet_b0._fc.in_features, 2).to(device) #마지막의 fc 레이어를 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3b17bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]           6,912\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "MemoryEfficientSwish-3         [-1, 32, 112, 112]               0\n",
      "         ZeroPad2d-4         [-1, 32, 114, 114]               0\n",
      "Conv2dStaticSamePadding-5         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-6         [-1, 32, 112, 112]              64\n",
      "MemoryEfficientSwish-7         [-1, 32, 112, 112]               0\n",
      "          Identity-8             [-1, 32, 1, 1]               0\n",
      "Conv2dStaticSamePadding-9              [-1, 8, 1, 1]             264\n",
      "MemoryEfficientSwish-10              [-1, 8, 1, 1]               0\n",
      "         Identity-11              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-12             [-1, 32, 1, 1]             288\n",
      "         Identity-13         [-1, 32, 112, 112]               0\n",
      "Conv2dStaticSamePadding-14         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-15         [-1, 16, 112, 112]              32\n",
      "      MBConvBlock-16         [-1, 16, 112, 112]               0\n",
      "         Identity-17         [-1, 16, 112, 112]               0\n",
      "Conv2dStaticSamePadding-18         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-19         [-1, 96, 112, 112]             192\n",
      "MemoryEfficientSwish-20         [-1, 96, 112, 112]               0\n",
      "        ZeroPad2d-21         [-1, 96, 113, 113]               0\n",
      "Conv2dStaticSamePadding-22           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-23           [-1, 96, 56, 56]             192\n",
      "MemoryEfficientSwish-24           [-1, 96, 56, 56]               0\n",
      "         Identity-25             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-26              [-1, 4, 1, 1]             388\n",
      "MemoryEfficientSwish-27              [-1, 4, 1, 1]               0\n",
      "         Identity-28              [-1, 4, 1, 1]               0\n",
      "Conv2dStaticSamePadding-29             [-1, 96, 1, 1]             480\n",
      "         Identity-30           [-1, 96, 56, 56]               0\n",
      "Conv2dStaticSamePadding-31           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-32           [-1, 24, 56, 56]              48\n",
      "      MBConvBlock-33           [-1, 24, 56, 56]               0\n",
      "         Identity-34           [-1, 24, 56, 56]               0\n",
      "Conv2dStaticSamePadding-35          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-36          [-1, 144, 56, 56]             288\n",
      "MemoryEfficientSwish-37          [-1, 144, 56, 56]               0\n",
      "        ZeroPad2d-38          [-1, 144, 58, 58]               0\n",
      "Conv2dStaticSamePadding-39          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-40          [-1, 144, 56, 56]             288\n",
      "MemoryEfficientSwish-41          [-1, 144, 56, 56]               0\n",
      "         Identity-42            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-43              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-44              [-1, 6, 1, 1]               0\n",
      "         Identity-45              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-46            [-1, 144, 1, 1]           1,008\n",
      "         Identity-47          [-1, 144, 56, 56]               0\n",
      "Conv2dStaticSamePadding-48           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-49           [-1, 24, 56, 56]              48\n",
      "      MBConvBlock-50           [-1, 24, 56, 56]               0\n",
      "         Identity-51           [-1, 24, 56, 56]               0\n",
      "Conv2dStaticSamePadding-52          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-53          [-1, 144, 56, 56]             288\n",
      "MemoryEfficientSwish-54          [-1, 144, 56, 56]               0\n",
      "        ZeroPad2d-55          [-1, 144, 59, 59]               0\n",
      "Conv2dStaticSamePadding-56          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-57          [-1, 144, 28, 28]             288\n",
      "MemoryEfficientSwish-58          [-1, 144, 28, 28]               0\n",
      "         Identity-59            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-60              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-61              [-1, 6, 1, 1]               0\n",
      "         Identity-62              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-63            [-1, 144, 1, 1]           1,008\n",
      "         Identity-64          [-1, 144, 28, 28]               0\n",
      "Conv2dStaticSamePadding-65           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-66           [-1, 40, 28, 28]              80\n",
      "      MBConvBlock-67           [-1, 40, 28, 28]               0\n",
      "         Identity-68           [-1, 40, 28, 28]               0\n",
      "Conv2dStaticSamePadding-69          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-70          [-1, 240, 28, 28]             480\n",
      "MemoryEfficientSwish-71          [-1, 240, 28, 28]               0\n",
      "        ZeroPad2d-72          [-1, 240, 32, 32]               0\n",
      "Conv2dStaticSamePadding-73          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-74          [-1, 240, 28, 28]             480\n",
      "MemoryEfficientSwish-75          [-1, 240, 28, 28]               0\n",
      "         Identity-76            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-77             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-78             [-1, 10, 1, 1]               0\n",
      "         Identity-79             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-80            [-1, 240, 1, 1]           2,640\n",
      "         Identity-81          [-1, 240, 28, 28]               0\n",
      "Conv2dStaticSamePadding-82           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-83           [-1, 40, 28, 28]              80\n",
      "      MBConvBlock-84           [-1, 40, 28, 28]               0\n",
      "         Identity-85           [-1, 40, 28, 28]               0\n",
      "Conv2dStaticSamePadding-86          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-87          [-1, 240, 28, 28]             480\n",
      "MemoryEfficientSwish-88          [-1, 240, 28, 28]               0\n",
      "        ZeroPad2d-89          [-1, 240, 29, 29]               0\n",
      "Conv2dStaticSamePadding-90          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-91          [-1, 240, 14, 14]             480\n",
      "MemoryEfficientSwish-92          [-1, 240, 14, 14]               0\n",
      "         Identity-93            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-94             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-95             [-1, 10, 1, 1]               0\n",
      "         Identity-96             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-97            [-1, 240, 1, 1]           2,640\n",
      "         Identity-98          [-1, 240, 14, 14]               0\n",
      "Conv2dStaticSamePadding-99           [-1, 80, 14, 14]          19,200\n",
      "     BatchNorm2d-100           [-1, 80, 14, 14]             160\n",
      "     MBConvBlock-101           [-1, 80, 14, 14]               0\n",
      "        Identity-102           [-1, 80, 14, 14]               0\n",
      "Conv2dStaticSamePadding-103          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-104          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-105          [-1, 480, 14, 14]               0\n",
      "       ZeroPad2d-106          [-1, 480, 16, 16]               0\n",
      "Conv2dStaticSamePadding-107          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-108          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-109          [-1, 480, 14, 14]               0\n",
      "        Identity-110            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-111             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-112             [-1, 20, 1, 1]               0\n",
      "        Identity-113             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-114            [-1, 480, 1, 1]          10,080\n",
      "        Identity-115          [-1, 480, 14, 14]               0\n",
      "Conv2dStaticSamePadding-116           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-117           [-1, 80, 14, 14]             160\n",
      "     MBConvBlock-118           [-1, 80, 14, 14]               0\n",
      "        Identity-119           [-1, 80, 14, 14]               0\n",
      "Conv2dStaticSamePadding-120          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-121          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-122          [-1, 480, 14, 14]               0\n",
      "       ZeroPad2d-123          [-1, 480, 16, 16]               0\n",
      "Conv2dStaticSamePadding-124          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-125          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-126          [-1, 480, 14, 14]               0\n",
      "        Identity-127            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-128             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-129             [-1, 20, 1, 1]               0\n",
      "        Identity-130             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-131            [-1, 480, 1, 1]          10,080\n",
      "        Identity-132          [-1, 480, 14, 14]               0\n",
      "Conv2dStaticSamePadding-133           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-134           [-1, 80, 14, 14]             160\n",
      "     MBConvBlock-135           [-1, 80, 14, 14]               0\n",
      "        Identity-136           [-1, 80, 14, 14]               0\n",
      "Conv2dStaticSamePadding-137          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-138          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-139          [-1, 480, 14, 14]               0\n",
      "       ZeroPad2d-140          [-1, 480, 18, 18]               0\n",
      "Conv2dStaticSamePadding-141          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-142          [-1, 480, 14, 14]             960\n",
      "MemoryEfficientSwish-143          [-1, 480, 14, 14]               0\n",
      "        Identity-144            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-145             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-146             [-1, 20, 1, 1]               0\n",
      "        Identity-147             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-148            [-1, 480, 1, 1]          10,080\n",
      "        Identity-149          [-1, 480, 14, 14]               0\n",
      "Conv2dStaticSamePadding-150          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-151          [-1, 112, 14, 14]             224\n",
      "     MBConvBlock-152          [-1, 112, 14, 14]               0\n",
      "        Identity-153          [-1, 112, 14, 14]               0\n",
      "Conv2dStaticSamePadding-154          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-155          [-1, 672, 14, 14]           1,344\n",
      "MemoryEfficientSwish-156          [-1, 672, 14, 14]               0\n",
      "       ZeroPad2d-157          [-1, 672, 18, 18]               0\n",
      "Conv2dStaticSamePadding-158          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-159          [-1, 672, 14, 14]           1,344\n",
      "MemoryEfficientSwish-160          [-1, 672, 14, 14]               0\n",
      "        Identity-161            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-162             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-163             [-1, 28, 1, 1]               0\n",
      "        Identity-164             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-165            [-1, 672, 1, 1]          19,488\n",
      "        Identity-166          [-1, 672, 14, 14]               0\n",
      "Conv2dStaticSamePadding-167          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-168          [-1, 112, 14, 14]             224\n",
      "     MBConvBlock-169          [-1, 112, 14, 14]               0\n",
      "        Identity-170          [-1, 112, 14, 14]               0\n",
      "Conv2dStaticSamePadding-171          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-172          [-1, 672, 14, 14]           1,344\n",
      "MemoryEfficientSwish-173          [-1, 672, 14, 14]               0\n",
      "       ZeroPad2d-174          [-1, 672, 18, 18]               0\n",
      "Conv2dStaticSamePadding-175          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-176          [-1, 672, 14, 14]           1,344\n",
      "MemoryEfficientSwish-177          [-1, 672, 14, 14]               0\n",
      "        Identity-178            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-179             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-180             [-1, 28, 1, 1]               0\n",
      "        Identity-181             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-182            [-1, 672, 1, 1]          19,488\n",
      "        Identity-183          [-1, 672, 14, 14]               0\n",
      "Conv2dStaticSamePadding-184          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-185          [-1, 112, 14, 14]             224\n",
      "     MBConvBlock-186          [-1, 112, 14, 14]               0\n",
      "        Identity-187          [-1, 112, 14, 14]               0\n",
      "Conv2dStaticSamePadding-188          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-189          [-1, 672, 14, 14]           1,344\n",
      "MemoryEfficientSwish-190          [-1, 672, 14, 14]               0\n",
      "       ZeroPad2d-191          [-1, 672, 17, 17]               0\n",
      "Conv2dStaticSamePadding-192            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-193            [-1, 672, 7, 7]           1,344\n",
      "MemoryEfficientSwish-194            [-1, 672, 7, 7]               0\n",
      "        Identity-195            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-196             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-197             [-1, 28, 1, 1]               0\n",
      "        Identity-198             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-199            [-1, 672, 1, 1]          19,488\n",
      "        Identity-200            [-1, 672, 7, 7]               0\n",
      "Conv2dStaticSamePadding-201            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-202            [-1, 192, 7, 7]             384\n",
      "     MBConvBlock-203            [-1, 192, 7, 7]               0\n",
      "        Identity-204            [-1, 192, 7, 7]               0\n",
      "Conv2dStaticSamePadding-205           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-206           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-207           [-1, 1152, 7, 7]               0\n",
      "       ZeroPad2d-208         [-1, 1152, 11, 11]               0\n",
      "Conv2dStaticSamePadding-209           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-210           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-211           [-1, 1152, 7, 7]               0\n",
      "        Identity-212           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-213             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-214             [-1, 48, 1, 1]               0\n",
      "        Identity-215             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-216           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-217           [-1, 1152, 7, 7]               0\n",
      "Conv2dStaticSamePadding-218            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-219            [-1, 192, 7, 7]             384\n",
      "     MBConvBlock-220            [-1, 192, 7, 7]               0\n",
      "        Identity-221            [-1, 192, 7, 7]               0\n",
      "Conv2dStaticSamePadding-222           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-224           [-1, 1152, 7, 7]               0\n",
      "       ZeroPad2d-225         [-1, 1152, 11, 11]               0\n",
      "Conv2dStaticSamePadding-226           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-227           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-228           [-1, 1152, 7, 7]               0\n",
      "        Identity-229           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-230             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-231             [-1, 48, 1, 1]               0\n",
      "        Identity-232             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-233           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-234           [-1, 1152, 7, 7]               0\n",
      "Conv2dStaticSamePadding-235            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-236            [-1, 192, 7, 7]             384\n",
      "     MBConvBlock-237            [-1, 192, 7, 7]               0\n",
      "        Identity-238            [-1, 192, 7, 7]               0\n",
      "Conv2dStaticSamePadding-239           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-240           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-241           [-1, 1152, 7, 7]               0\n",
      "       ZeroPad2d-242         [-1, 1152, 11, 11]               0\n",
      "Conv2dStaticSamePadding-243           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-244           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-245           [-1, 1152, 7, 7]               0\n",
      "        Identity-246           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-247             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-248             [-1, 48, 1, 1]               0\n",
      "        Identity-249             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-250           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-251           [-1, 1152, 7, 7]               0\n",
      "Conv2dStaticSamePadding-252            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-253            [-1, 192, 7, 7]             384\n",
      "     MBConvBlock-254            [-1, 192, 7, 7]               0\n",
      "        Identity-255            [-1, 192, 7, 7]               0\n",
      "Conv2dStaticSamePadding-256           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-257           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-258           [-1, 1152, 7, 7]               0\n",
      "       ZeroPad2d-259           [-1, 1152, 9, 9]               0\n",
      "Conv2dStaticSamePadding-260           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-261           [-1, 1152, 7, 7]           2,304\n",
      "MemoryEfficientSwish-262           [-1, 1152, 7, 7]               0\n",
      "        Identity-263           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-264             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-265             [-1, 48, 1, 1]               0\n",
      "        Identity-266             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-267           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-268           [-1, 1152, 7, 7]               0\n",
      "Conv2dStaticSamePadding-269            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-270            [-1, 320, 7, 7]             640\n",
      "     MBConvBlock-271            [-1, 320, 7, 7]               0\n",
      "        Identity-272            [-1, 320, 7, 7]               0\n",
      "Conv2dStaticSamePadding-273           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-274           [-1, 1280, 7, 7]           2,560\n",
      "MemoryEfficientSwish-275           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-276           [-1, 1280, 1, 1]               0\n",
      "         Dropout-277                 [-1, 1280]               0\n",
      "          Linear-278                    [-1, 2]           2,562\n",
      "================================================================\n",
      "Total params: 4,016,158\n",
      "Trainable params: 4,016,158\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 4.59\n",
      "Forward/backward pass size (MB): 211.63\n",
      "Params size (MB): 15.32\n",
      "Estimated Total Size (MB): 231.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary # 모델 아키텍쳐 확인하는 함수\n",
    "\n",
    "summary(efficientnet_b0, input_size = (24, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3af44ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.000005\n",
    "\n",
    "optimizer = torch.optim.Adam(efficientnet_b0.parameters(), lr = lr, weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc22b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:08,  3.62s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 0/30 Loss : 0.698, Accuracy : 53.348%, AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 0/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:02,  3.31s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 1/30 Loss : 0.699, Accuracy : 51.175%, AUROC : 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 1/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:00,  3.20s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 2/30 Loss : 0.705, Accuracy : 50.06%, AUROC : 0.4714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 2/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:06,  3.52s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 3/30 Loss : 0.696, Accuracy : 51.821%, AUROC : 0.27142857142857146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 3/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:07,  3.53s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 4/30 Loss : 0.694, Accuracy : 55.33%, AUROC : 0.5142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 4/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.42s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 5/30 Loss : 0.689, Accuracy : 57.194%, AUROC : 0.6428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 5/30 Loss : 0.694, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:07,  3.56s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 6/30 Loss : 0.688, Accuracy : 58.081%, AUROC : 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 6/30 Loss : 0.693, Accuracy : 44.576% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.47s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 7/30 Loss : 0.69, Accuracy : 56.211%, AUROC : 0.34285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 7/30 Loss : 0.693, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.46s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 8/30 Loss : 0.686, Accuracy : 58.334%, AUROC : 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 8/30 Loss : 0.693, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:15,  3.96s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 9/30 Loss : 0.692, Accuracy : 55.623%, AUROC : 0.41428571428571426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 9/30 Loss : 0.692, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:16,  4.03s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 10/30 Loss : 0.694, Accuracy : 55.5%, AUROC : 0.6857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 10/30 Loss : 0.691, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:12,  3.82s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 11/30 Loss : 0.69, Accuracy : 54.73%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 11/30 Loss : 0.69, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:09,  3.66s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 12/30 Loss : 0.693, Accuracy : 56.052%, AUROC : 0.6571428571428573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 12/30 Loss : 0.691, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:11,  3.76s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 13/30 Loss : 0.683, Accuracy : 56.602%, AUROC : 0.5571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 13/30 Loss : 0.69, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:01,  3.26s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 14/30 Loss : 0.685, Accuracy : 54.386%, AUROC : 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 14/30 Loss : 0.689, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:21,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 15/30 Loss : 0.697, Accuracy : 50.014%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 15/30 Loss : 0.688, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:03,  3.35s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 16/30 Loss : 0.686, Accuracy : 52.898%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 16/30 Loss : 0.688, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.44s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 17/30 Loss : 0.681, Accuracy : 57.539%, AUROC : 0.31428571428571433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 17/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:13,  3.86s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 18/30 Loss : 0.69, Accuracy : 57.257%, AUROC : 0.34285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 18/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.37s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 19/30 Loss : 0.693, Accuracy : 54.812%, AUROC : 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 19/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:11,  3.78s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 20/30 Loss : 0.693, Accuracy : 54.674%, AUROC : 0.31428571428571433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 20/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.44s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 21/30 Loss : 0.676, Accuracy : 58.14%, AUROC : 0.7571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 21/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:05,  3.46s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 22/30 Loss : 0.685, Accuracy : 55.26%, AUROC : 0.5571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 22/30 Loss : 0.688, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:12,  3.79s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 23/30 Loss : 0.682, Accuracy : 56.037%, AUROC : 0.48571428571428565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 23/30 Loss : 0.691, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:10,  3.70s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 24/30 Loss : 0.681, Accuracy : 55.729%, AUROC : 0.5571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 24/30 Loss : 0.689, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.41s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 25/30 Loss : 0.685, Accuracy : 56.848%, AUROC : 0.5857142857142856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 25/30 Loss : 0.687, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:06,  3.51s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 26/30 Loss : 0.691, Accuracy : 54.224%, AUROC : 0.5142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 26/30 Loss : 0.684, Accuracy : 55.424% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:03,  3.32s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 27/30 Loss : 0.676, Accuracy : 55.384%, AUROC : 0.6285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 27/30 Loss : 0.685, Accuracy : 55.666% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:04,  3.40s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 28/30 Loss : 0.687, Accuracy : 56.8%, AUROC : 0.2142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 28/30 Loss : 0.689, Accuracy : 51.346% \n",
      ", AUROC : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n",
      "19it [01:10,  3.71s/it]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\1447404477.py:32: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  label = int(patient_aneurysm.values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset 29/30 Loss : 0.681, Accuracy : 56.229%, AUROC : 0.5571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_17048\\189222305.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valid_label = torch.tensor(valid_label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validset 29/30 Loss : 0.694, Accuracy : 46.771% \n",
      ", AUROC : 0.5\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "epochs = 30\n",
    "criterion = nn.CrossEntropyLoss().to(device) # cost function\n",
    "\n",
    "train_acc_lst, train_loss_lst, test_acc_lst, test_loss_lst= [], [], [], []\n",
    "state={}\n",
    "train_auroc_lst= []\n",
    "test_auroc_lst = []\n",
    "y_pred = 0\n",
    "y_true = 0\n",
    "\n",
    "# 에포크 : training + evaluation\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "#     # ----------------- TRAINING  -------------------- \n",
    "#     # training 모델로 설정\n",
    "    efficientnet_b0.train()\n",
    "    for i, (train_imgs, train_labels) in tqdm(enumerate(train_loader)):\n",
    "        # gpu에 할당\n",
    "#         print(len(train_img))\n",
    "#         print(len(train_label))\n",
    "        \n",
    "#         print(len(train_imgs))  # 이미지 리스트의 길이 출력\n",
    "        \n",
    "        \n",
    "        y_true = train_labels.numpy()\n",
    "        # 이미지 텐서 생성\n",
    "        train_images = torch.cat((train_imgs), dim=1)\n",
    "        train_labels = torch.tensor(train_labels)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "#         print(train_images.shape)\n",
    "        \n",
    "#        24차원됨\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_img = train_images.to(device)\n",
    "        train_label = train_labels.to(device)\n",
    "        \n",
    "#         efficientnet_b0\n",
    "        \n",
    "        output = efficientnet_b0(train_img) # 모델에 입력\n",
    "        optimizer.zero_grad(set_to_none = True ) # 계산했던 가중치 초기화               \n",
    "        loss = criterion(output, train_label)\n",
    "        loss.backward() # 미분\n",
    "        optimizer.step() # 학습\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predictions = torch.max(output.data ,dim = 1) \n",
    "        y_pred = predictions.cpu().numpy()\n",
    "        \n",
    "        total += train_label.size(0)\n",
    "        correct += (predictions == train_label).sum().item()\n",
    "        train_acc += 100 * (correct / total)\n",
    "    \n",
    "    train_loss = round(train_loss/(i+1), 3) # 소수점 반올림\n",
    "    train_acc = round(train_acc/(i+1), 3)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    print(f'Trainset {epoch}/{epochs} Loss : {train_loss}, Accuracy : {train_acc}%, AUROC : {auroc}')\n",
    "    train_acc_lst.append(train_acc)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "  # -------------------------------------------------------------------------------------\n",
    "    test_loss = 0.0\n",
    "    corrects = 0\n",
    "    totals = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    \n",
    "#     print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    efficientnet_b0.eval()\n",
    "    for i, (valid_img, valid_label) in enumerate(valid_loader):\n",
    "        # gpu에 할당\n",
    "        \n",
    "        y_true = valid_label.numpy()\n",
    "        valid_img = torch.cat((valid_img), dim=1)\n",
    "        valid_label = torch.tensor(valid_label)\n",
    "        \n",
    "        valid_img = valid_img.to(device)\n",
    "        valid_label = valid_label.to(device)\n",
    "        \n",
    "        outputs = efficientnet_b0(valid_img) # 모델에 입력\n",
    "        losses = criterion(outputs, valid_label)\n",
    "        \n",
    "         # loss & acc\n",
    "        test_loss += losses.item()\n",
    "        _, predictions = torch.max(outputs.data ,dim = 1 )\n",
    "        y_pred = predictions.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        totals += valid_label.size(0)\n",
    "        corrects += (predictions == valid_label).sum().item()\n",
    "        test_acc += 100 * (corrects / totals)\n",
    "        \n",
    "    test_loss = round(test_loss/(i+1), 3) # 소수점 반올림\n",
    "    test_acc = round(test_acc/(i+1), 3)\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    print(f'Validset {epoch}/{epochs} Loss : {test_loss}, Accuracy : {test_acc}% \\n, AUROC : {auroc}')\n",
    "    test_loss_lst.append(test_loss)\n",
    "    test_acc_lst.append(test_acc)\n",
    "    test_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "    if np.max(test_acc_lst) <= test_acc:\n",
    "        state['epoch'] = epoch\n",
    "        state['net'] = efficientnet_b0.state_dict()\n",
    "\n",
    "        state['train_loss'] = train_loss\n",
    "        state['test_loss'] = test_loss\n",
    "\n",
    "        state['train_acc'] = train_acc\n",
    "        state['test_acc'] = test_acc\n",
    "# torch.save(state, '/content/drive/MyDrive/Colab Notebooks/dna/week6/efficientnet_b0{}_{}.pth'.format(str(state['epoch']), str(state['test_acc'])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70a855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a823c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39d871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f74be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
