{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d2d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "# from custom_8_3_h_w import Custom_dataset\n",
    "from torch.utils.data import DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bb9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6df3da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dhkim\\\\Desktop\\\\directory\\\\k-ium'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21580bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # device 배정\n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee88399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac89aa9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\dhkim\\Desktop\\directory\\k-ium\\data\\2023_k_ium_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6428f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train_set/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc0aa6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Aneurysm</th>\n",
       "      <th>L_ICA</th>\n",
       "      <th>R_ICA</th>\n",
       "      <th>L_PCOM</th>\n",
       "      <th>R_PCOM</th>\n",
       "      <th>L_AntChor</th>\n",
       "      <th>R_AntChor</th>\n",
       "      <th>L_ACA</th>\n",
       "      <th>R_ACA</th>\n",
       "      <th>...</th>\n",
       "      <th>R_MCA</th>\n",
       "      <th>L_VA</th>\n",
       "      <th>R_VA</th>\n",
       "      <th>L_PICA</th>\n",
       "      <th>R_PICA</th>\n",
       "      <th>L_SCA</th>\n",
       "      <th>R_SCA</th>\n",
       "      <th>BA</th>\n",
       "      <th>L_PCA</th>\n",
       "      <th>R_PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2608</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>2609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>2610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1127 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Index  Aneurysm  L_ICA  R_ICA  L_PCOM  R_PCOM  L_AntChor  R_AntChor  \\\n",
       "0      1001         0      0      0       0       0          0          0   \n",
       "1      1002         1      0      0       0       0          0          0   \n",
       "2      1004         1      0      0       0       1          0          0   \n",
       "3      1005         1      0      0       0       1          0          1   \n",
       "4      1006         0      0      0       0       0          0          0   \n",
       "...     ...       ...    ...    ...     ...     ...        ...        ...   \n",
       "1122   2607         1      0      0       0       0          0          0   \n",
       "1123   2608         1      0      0       0       0          0          0   \n",
       "1124   2609         0      0      0       0       0          0          0   \n",
       "1125   2610         0      0      0       0       0          0          0   \n",
       "1126   2611         0      0      0       0       0          0          0   \n",
       "\n",
       "      L_ACA  R_ACA  ...  R_MCA  L_VA  R_VA  L_PICA  R_PICA  L_SCA  R_SCA  BA  \\\n",
       "0         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "2         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "3         0      0  ...      1     0     0       0       0      0      1   0   \n",
       "4         0      0  ...      0     0     0       0       0      0      0   0   \n",
       "...     ...    ...  ...    ...   ...   ...     ...     ...    ...    ...  ..   \n",
       "1122      0      0  ...      0     0     1       0       0      0      0   0   \n",
       "1123      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1124      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1125      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "1126      0      0  ...      0     0     0       0       0      0      0   0   \n",
       "\n",
       "      L_PCA  R_PCA  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "1122      0      0  \n",
       "1123      0      0  \n",
       "1124      0      0  \n",
       "1125      0      0  \n",
       "1126      0      0  \n",
       "\n",
       "[1127 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03a575d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    604\n",
       "1    523\n",
       "Name: Aneurysm, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv['Aneurysm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f882b2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1001,\n",
       " 1002,\n",
       " 1004,\n",
       " 1005,\n",
       " 1006,\n",
       " 1007,\n",
       " 1008,\n",
       " 1009,\n",
       " 1010,\n",
       " 1011,\n",
       " 1012,\n",
       " 1013,\n",
       " 1015,\n",
       " 1016,\n",
       " 1017,\n",
       " 1018,\n",
       " 1019,\n",
       " 1020,\n",
       " 1021,\n",
       " 1022,\n",
       " 1023,\n",
       " 1024,\n",
       " 1025,\n",
       " 1026,\n",
       " 1027,\n",
       " 1028,\n",
       " 1029,\n",
       " 1030,\n",
       " 1031,\n",
       " 1032,\n",
       " 1033,\n",
       " 1034,\n",
       " 1035,\n",
       " 1036,\n",
       " 1037,\n",
       " 1038,\n",
       " 1039,\n",
       " 1040,\n",
       " 1041,\n",
       " 1042,\n",
       " 1043,\n",
       " 1044,\n",
       " 1045,\n",
       " 1046,\n",
       " 1047,\n",
       " 1048,\n",
       " 1049,\n",
       " 1050,\n",
       " 1051,\n",
       " 1052,\n",
       " 1053,\n",
       " 1054,\n",
       " 1055,\n",
       " 1056,\n",
       " 1057,\n",
       " 1058,\n",
       " 1059,\n",
       " 1060,\n",
       " 1061,\n",
       " 1062,\n",
       " 1063,\n",
       " 1064,\n",
       " 1065,\n",
       " 1066,\n",
       " 1067,\n",
       " 1068,\n",
       " 1069,\n",
       " 1070,\n",
       " 1071,\n",
       " 1072,\n",
       " 1073,\n",
       " 1074,\n",
       " 1075,\n",
       " 1076,\n",
       " 1077,\n",
       " 1078,\n",
       " 1079,\n",
       " 1080,\n",
       " 1081,\n",
       " 1082,\n",
       " 1083,\n",
       " 1084,\n",
       " 1085,\n",
       " 1086,\n",
       " 1087,\n",
       " 1088,\n",
       " 1089,\n",
       " 1090,\n",
       " 1091,\n",
       " 1092,\n",
       " 1093,\n",
       " 1094,\n",
       " 1095,\n",
       " 1096,\n",
       " 1097,\n",
       " 1098,\n",
       " 1099,\n",
       " 1100,\n",
       " 1101,\n",
       " 1102,\n",
       " 1103,\n",
       " 1104,\n",
       " 1105,\n",
       " 1106,\n",
       " 1107,\n",
       " 1108,\n",
       " 1109,\n",
       " 1110,\n",
       " 1111,\n",
       " 1114,\n",
       " 1115,\n",
       " 1116,\n",
       " 1117,\n",
       " 1118,\n",
       " 1119,\n",
       " 1120,\n",
       " 1121,\n",
       " 1122,\n",
       " 1123,\n",
       " 1124,\n",
       " 1125,\n",
       " 1126,\n",
       " 1127,\n",
       " 1128,\n",
       " 1129,\n",
       " 1130,\n",
       " 1131,\n",
       " 1132,\n",
       " 1133,\n",
       " 1134,\n",
       " 1135,\n",
       " 1136,\n",
       " 1138,\n",
       " 1139,\n",
       " 1140,\n",
       " 1142,\n",
       " 1143,\n",
       " 1144,\n",
       " 1145,\n",
       " 1146,\n",
       " 1148,\n",
       " 1149,\n",
       " 1150,\n",
       " 1151,\n",
       " 1152,\n",
       " 1153,\n",
       " 1154,\n",
       " 1155,\n",
       " 1156,\n",
       " 1157,\n",
       " 1158,\n",
       " 1159,\n",
       " 1160,\n",
       " 1161,\n",
       " 1162,\n",
       " 1163,\n",
       " 1164,\n",
       " 1165,\n",
       " 1166,\n",
       " 1167,\n",
       " 1168,\n",
       " 1169,\n",
       " 1170,\n",
       " 1171,\n",
       " 1172,\n",
       " 1173,\n",
       " 1174,\n",
       " 1175,\n",
       " 1176,\n",
       " 1177,\n",
       " 1178,\n",
       " 1179,\n",
       " 1180,\n",
       " 1181,\n",
       " 1182,\n",
       " 1183,\n",
       " 1184,\n",
       " 1185,\n",
       " 1186,\n",
       " 1188,\n",
       " 1189,\n",
       " 1190,\n",
       " 1191,\n",
       " 1192,\n",
       " 1193,\n",
       " 1194,\n",
       " 1195,\n",
       " 1196,\n",
       " 1197,\n",
       " 1198,\n",
       " 1199,\n",
       " 1201,\n",
       " 1202,\n",
       " 1203,\n",
       " 1204,\n",
       " 1205,\n",
       " 1207,\n",
       " 1208,\n",
       " 1209,\n",
       " 1210,\n",
       " 1211,\n",
       " 1212,\n",
       " 1214,\n",
       " 1215,\n",
       " 1216,\n",
       " 1217,\n",
       " 1218,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1223,\n",
       " 1224,\n",
       " 1225,\n",
       " 1226,\n",
       " 1227,\n",
       " 1228,\n",
       " 1229,\n",
       " 1230,\n",
       " 1231,\n",
       " 1232,\n",
       " 1233,\n",
       " 1234,\n",
       " 1235,\n",
       " 1236,\n",
       " 1237,\n",
       " 1238,\n",
       " 1239,\n",
       " 1240,\n",
       " 1242,\n",
       " 1243,\n",
       " 1244,\n",
       " 1245,\n",
       " 1246,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1250,\n",
       " 1251,\n",
       " 1252,\n",
       " 1253,\n",
       " 1254,\n",
       " 1255,\n",
       " 1256,\n",
       " 1257,\n",
       " 1258,\n",
       " 1259,\n",
       " 1260,\n",
       " 1261,\n",
       " 1262,\n",
       " 1263,\n",
       " 1264,\n",
       " 1265,\n",
       " 1266,\n",
       " 1267,\n",
       " 1268,\n",
       " 1269,\n",
       " 1270,\n",
       " 1271,\n",
       " 1272,\n",
       " 1273,\n",
       " 1274,\n",
       " 1275,\n",
       " 1276,\n",
       " 1278,\n",
       " 1279,\n",
       " 1280,\n",
       " 1281,\n",
       " 1282,\n",
       " 1283,\n",
       " 1284,\n",
       " 1285,\n",
       " 1286,\n",
       " 1287,\n",
       " 1288,\n",
       " 1289,\n",
       " 1290,\n",
       " 1291,\n",
       " 1292,\n",
       " 1293,\n",
       " 1294,\n",
       " 1295,\n",
       " 1296,\n",
       " 1297,\n",
       " 1299,\n",
       " 1300,\n",
       " 1301,\n",
       " 1302,\n",
       " 1303,\n",
       " 1304,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1308,\n",
       " 1309,\n",
       " 1310,\n",
       " 1311,\n",
       " 1312,\n",
       " 1313,\n",
       " 1314,\n",
       " 1315,\n",
       " 1316,\n",
       " 1317,\n",
       " 1318,\n",
       " 1319,\n",
       " 1320,\n",
       " 1321,\n",
       " 1323,\n",
       " 1324,\n",
       " 1325,\n",
       " 1326,\n",
       " 1327,\n",
       " 1328,\n",
       " 1329,\n",
       " 1330,\n",
       " 1331,\n",
       " 1332,\n",
       " 1333,\n",
       " 1334,\n",
       " 1335,\n",
       " 1336,\n",
       " 1337,\n",
       " 1338,\n",
       " 1339,\n",
       " 1340,\n",
       " 1341,\n",
       " 1342,\n",
       " 1343,\n",
       " 1344,\n",
       " 1345,\n",
       " 1346,\n",
       " 1347,\n",
       " 1348,\n",
       " 1349,\n",
       " 1350,\n",
       " 1351,\n",
       " 1352,\n",
       " 1353,\n",
       " 1354,\n",
       " 1355,\n",
       " 1356,\n",
       " 1357,\n",
       " 1358,\n",
       " 1359,\n",
       " 1360,\n",
       " 1361,\n",
       " 1362,\n",
       " 1363,\n",
       " 1364,\n",
       " 1365,\n",
       " 1366,\n",
       " 1367,\n",
       " 1368,\n",
       " 1370,\n",
       " 1371,\n",
       " 1372,\n",
       " 1373,\n",
       " 1374,\n",
       " 1375,\n",
       " 1376,\n",
       " 1377,\n",
       " 1378,\n",
       " 1379,\n",
       " 1380,\n",
       " 1381,\n",
       " 1382,\n",
       " 1383,\n",
       " 1384,\n",
       " 1385,\n",
       " 1386,\n",
       " 1387,\n",
       " 1388,\n",
       " 1389,\n",
       " 1390,\n",
       " 1391,\n",
       " 1392,\n",
       " 1393,\n",
       " 1394,\n",
       " 1395,\n",
       " 1396,\n",
       " 1398,\n",
       " 1399,\n",
       " 1400,\n",
       " 1401,\n",
       " 1402,\n",
       " 1403,\n",
       " 1404,\n",
       " 1405,\n",
       " 1407,\n",
       " 1408,\n",
       " 1409,\n",
       " 1410,\n",
       " 1411,\n",
       " 1412,\n",
       " 1413,\n",
       " 1414,\n",
       " 1415,\n",
       " 1416,\n",
       " 1417,\n",
       " 1418,\n",
       " 1419,\n",
       " 1420,\n",
       " 1421,\n",
       " 1422,\n",
       " 1423,\n",
       " 1424,\n",
       " 1425,\n",
       " 1426,\n",
       " 1427,\n",
       " 1428,\n",
       " 1429,\n",
       " 1430,\n",
       " 1431,\n",
       " 1432,\n",
       " 1433,\n",
       " 1434,\n",
       " 1435,\n",
       " 1436,\n",
       " 1437,\n",
       " 1438,\n",
       " 1439,\n",
       " 1440,\n",
       " 1441,\n",
       " 1442,\n",
       " 1443,\n",
       " 1444,\n",
       " 1445,\n",
       " 1446,\n",
       " 1447,\n",
       " 1448,\n",
       " 1449,\n",
       " 1450,\n",
       " 1451,\n",
       " 1452,\n",
       " 1453,\n",
       " 1454,\n",
       " 1455,\n",
       " 1456,\n",
       " 1457,\n",
       " 1458,\n",
       " 1459,\n",
       " 1460,\n",
       " 1461,\n",
       " 1462,\n",
       " 1463,\n",
       " 1464,\n",
       " 1465,\n",
       " 1466,\n",
       " 1467,\n",
       " 1468,\n",
       " 1469,\n",
       " 1470,\n",
       " 1471,\n",
       " 1472,\n",
       " 1473,\n",
       " 1474,\n",
       " 1475,\n",
       " 1476,\n",
       " 1477,\n",
       " 1478,\n",
       " 1479,\n",
       " 1480,\n",
       " 1481,\n",
       " 1482,\n",
       " 1483,\n",
       " 1484,\n",
       " 1485,\n",
       " 1486,\n",
       " 1487,\n",
       " 1488,\n",
       " 1489,\n",
       " 1490,\n",
       " 1491,\n",
       " 1492,\n",
       " 1493,\n",
       " 1494,\n",
       " 1495,\n",
       " 1496,\n",
       " 1497,\n",
       " 1498,\n",
       " 1499,\n",
       " 1500,\n",
       " 1501,\n",
       " 1502,\n",
       " 1503,\n",
       " 1504,\n",
       " 1505,\n",
       " 1506,\n",
       " 1507,\n",
       " 1508,\n",
       " 1509,\n",
       " 1510,\n",
       " 1511,\n",
       " 1512,\n",
       " 1513,\n",
       " 1514,\n",
       " 1515,\n",
       " 1516,\n",
       " 1517,\n",
       " 1518,\n",
       " 1519,\n",
       " 1520,\n",
       " 1521,\n",
       " 1522,\n",
       " 1523,\n",
       " 1524,\n",
       " 1525,\n",
       " 1526,\n",
       " 1527,\n",
       " 1528,\n",
       " 1529,\n",
       " 1530,\n",
       " 1531,\n",
       " 1533,\n",
       " 1534,\n",
       " 1535,\n",
       " 1536,\n",
       " 1537,\n",
       " 1538,\n",
       " 1539,\n",
       " 1540,\n",
       " 1541,\n",
       " 1542,\n",
       " 1543,\n",
       " 1544,\n",
       " 1545,\n",
       " 1546,\n",
       " 1547,\n",
       " 1548,\n",
       " 1549,\n",
       " 1550,\n",
       " 1552,\n",
       " 1553,\n",
       " 1554,\n",
       " 1555,\n",
       " 1556,\n",
       " 1557,\n",
       " 1558,\n",
       " 1559,\n",
       " 1560,\n",
       " 1561,\n",
       " 1562,\n",
       " 1564,\n",
       " 1565,\n",
       " 1566,\n",
       " 1567,\n",
       " 1568,\n",
       " 1569,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022,\n",
       " 2023,\n",
       " 2024,\n",
       " 2025,\n",
       " 2026,\n",
       " 2027,\n",
       " 2028,\n",
       " 2029,\n",
       " 2030,\n",
       " 2031,\n",
       " 2032,\n",
       " 2033,\n",
       " 2034,\n",
       " 2035,\n",
       " 2036,\n",
       " 2037,\n",
       " 2038,\n",
       " 2039,\n",
       " 2040,\n",
       " 2041,\n",
       " 2042,\n",
       " 2043,\n",
       " 2044,\n",
       " 2045,\n",
       " 2046,\n",
       " 2047,\n",
       " 2048,\n",
       " 2049,\n",
       " 2050,\n",
       " 2051,\n",
       " 2052,\n",
       " 2053,\n",
       " 2054,\n",
       " 2055,\n",
       " 2056,\n",
       " 2057,\n",
       " 2058,\n",
       " 2059,\n",
       " 2060,\n",
       " 2061,\n",
       " 2062,\n",
       " 2063,\n",
       " 2064,\n",
       " 2065,\n",
       " 2066,\n",
       " 2067,\n",
       " 2068,\n",
       " 2069,\n",
       " 2070,\n",
       " 2071,\n",
       " 2072,\n",
       " 2073,\n",
       " 2074,\n",
       " 2075,\n",
       " 2076,\n",
       " 2077,\n",
       " 2078,\n",
       " 2079,\n",
       " 2080,\n",
       " 2081,\n",
       " 2082,\n",
       " 2083,\n",
       " 2084,\n",
       " 2085,\n",
       " 2086,\n",
       " 2087,\n",
       " 2088,\n",
       " 2089,\n",
       " 2090,\n",
       " 2091,\n",
       " 2092,\n",
       " 2093,\n",
       " 2094,\n",
       " 2095,\n",
       " 2096,\n",
       " 2097,\n",
       " 2098,\n",
       " 2099,\n",
       " 2100,\n",
       " 2101,\n",
       " 2102,\n",
       " 2103,\n",
       " 2104,\n",
       " 2105,\n",
       " 2106,\n",
       " 2107,\n",
       " 2108,\n",
       " 2109,\n",
       " 2110,\n",
       " 2112,\n",
       " 2113,\n",
       " 2114,\n",
       " 2115,\n",
       " 2116,\n",
       " 2117,\n",
       " 2118,\n",
       " 2119,\n",
       " 2120,\n",
       " 2121,\n",
       " 2122,\n",
       " 2123,\n",
       " 2124,\n",
       " 2125,\n",
       " 2126,\n",
       " 2127,\n",
       " 2128,\n",
       " 2129,\n",
       " 2130,\n",
       " 2132,\n",
       " 2133,\n",
       " 2134,\n",
       " 2135,\n",
       " 2136,\n",
       " 2137,\n",
       " 2139,\n",
       " 2140,\n",
       " 2141,\n",
       " 2142,\n",
       " 2143,\n",
       " 2144,\n",
       " 2145,\n",
       " 2146,\n",
       " 2147,\n",
       " 2148,\n",
       " 2149,\n",
       " 2150,\n",
       " 2151,\n",
       " 2152,\n",
       " 2153,\n",
       " 2155,\n",
       " 2156,\n",
       " 2157,\n",
       " 2158,\n",
       " 2159,\n",
       " 2160,\n",
       " 2161,\n",
       " 2162,\n",
       " 2163,\n",
       " 2164,\n",
       " 2165,\n",
       " 2166,\n",
       " 2167,\n",
       " 2168,\n",
       " 2169,\n",
       " 2170,\n",
       " 2172,\n",
       " 2173,\n",
       " 2174,\n",
       " 2175,\n",
       " 2176,\n",
       " 2177,\n",
       " 2179,\n",
       " 2180,\n",
       " 2181,\n",
       " 2182,\n",
       " 2183,\n",
       " 2184,\n",
       " 2185,\n",
       " 2186,\n",
       " 2187,\n",
       " 2188,\n",
       " 2189,\n",
       " 2190,\n",
       " 2191,\n",
       " 2192,\n",
       " 2193,\n",
       " 2194,\n",
       " 2195,\n",
       " 2196,\n",
       " 2198,\n",
       " 2199,\n",
       " 2200,\n",
       " 2201,\n",
       " 2202,\n",
       " 2203,\n",
       " 2204,\n",
       " 2205,\n",
       " 2206,\n",
       " 2207,\n",
       " 2208,\n",
       " 2209,\n",
       " 2210,\n",
       " 2211,\n",
       " 2212,\n",
       " 2213,\n",
       " 2214,\n",
       " 2215,\n",
       " 2216,\n",
       " 2217,\n",
       " 2218,\n",
       " 2219,\n",
       " 2220,\n",
       " 2221,\n",
       " 2222,\n",
       " 2223,\n",
       " 2224,\n",
       " 2225,\n",
       " 2226,\n",
       " 2227,\n",
       " 2228,\n",
       " 2229,\n",
       " 2230,\n",
       " 2231,\n",
       " 2232,\n",
       " 2233,\n",
       " 2234,\n",
       " 2235,\n",
       " 2236,\n",
       " 2237,\n",
       " 2238,\n",
       " 2239,\n",
       " 2240,\n",
       " 2241,\n",
       " 2242,\n",
       " 2244,\n",
       " 2245,\n",
       " 2246,\n",
       " 2247,\n",
       " 2248,\n",
       " 2249,\n",
       " 2250,\n",
       " 2252,\n",
       " 2253,\n",
       " 2254,\n",
       " 2255,\n",
       " 2256,\n",
       " 2257,\n",
       " 2258,\n",
       " 2259,\n",
       " 2260,\n",
       " 2261,\n",
       " 2262,\n",
       " 2263,\n",
       " 2264,\n",
       " 2265,\n",
       " 2266,\n",
       " 2267,\n",
       " 2268,\n",
       " 2269,\n",
       " 2270,\n",
       " 2271,\n",
       " 2272,\n",
       " 2273,\n",
       " 2274,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2281,\n",
       " 2282,\n",
       " 2283,\n",
       " 2284,\n",
       " 2285,\n",
       " 2286,\n",
       " 2287,\n",
       " 2288,\n",
       " 2289,\n",
       " 2290,\n",
       " 2291,\n",
       " 2292,\n",
       " 2293,\n",
       " 2294,\n",
       " 2295,\n",
       " 2296,\n",
       " 2297,\n",
       " 2298,\n",
       " 2299,\n",
       " 2300,\n",
       " 2301,\n",
       " 2302,\n",
       " 2303,\n",
       " 2304,\n",
       " 2305,\n",
       " 2306,\n",
       " 2307,\n",
       " 2308,\n",
       " 2309,\n",
       " 2310,\n",
       " 2311,\n",
       " 2312,\n",
       " 2313,\n",
       " 2314,\n",
       " 2315,\n",
       " 2316,\n",
       " 2317,\n",
       " 2318,\n",
       " 2319,\n",
       " 2320,\n",
       " 2321,\n",
       " 2322,\n",
       " 2323,\n",
       " 2324,\n",
       " 2325,\n",
       " 2326,\n",
       " 2327,\n",
       " 2328,\n",
       " 2329,\n",
       " 2330,\n",
       " 2331,\n",
       " 2332,\n",
       " 2333,\n",
       " 2334,\n",
       " 2335,\n",
       " 2336,\n",
       " 2338,\n",
       " 2339,\n",
       " 2340,\n",
       " 2341,\n",
       " 2342,\n",
       " 2343,\n",
       " 2344,\n",
       " 2345,\n",
       " 2346,\n",
       " 2347,\n",
       " 2348,\n",
       " 2349,\n",
       " 2350,\n",
       " 2351,\n",
       " 2352,\n",
       " 2354,\n",
       " 2356,\n",
       " 2357,\n",
       " 2358,\n",
       " 2359,\n",
       " 2360,\n",
       " 2361,\n",
       " 2362,\n",
       " 2363,\n",
       " 2364,\n",
       " 2365,\n",
       " 2366,\n",
       " 2367,\n",
       " 2368,\n",
       " 2369,\n",
       " 2370,\n",
       " 2371,\n",
       " 2372,\n",
       " 2374,\n",
       " 2375,\n",
       " 2376,\n",
       " 2377,\n",
       " 2378,\n",
       " 2379,\n",
       " 2381,\n",
       " 2382,\n",
       " 2383,\n",
       " 2384,\n",
       " 2385,\n",
       " 2386,\n",
       " 2387,\n",
       " 2388,\n",
       " 2389,\n",
       " 2390,\n",
       " 2391,\n",
       " 2393,\n",
       " 2395,\n",
       " 2396,\n",
       " 2397,\n",
       " 2398,\n",
       " 2399,\n",
       " 2400,\n",
       " 2401,\n",
       " 2402,\n",
       " 2403,\n",
       " 2404,\n",
       " 2405,\n",
       " 2406,\n",
       " 2408,\n",
       " 2409,\n",
       " 2410,\n",
       " 2411,\n",
       " 2412,\n",
       " 2414,\n",
       " 2415,\n",
       " 2416,\n",
       " 2417,\n",
       " 2418,\n",
       " 2419,\n",
       " 2420,\n",
       " 2421,\n",
       " 2422,\n",
       " 2423,\n",
       " 2424,\n",
       " 2425,\n",
       " 2426,\n",
       " 2427,\n",
       " 2429,\n",
       " 2430,\n",
       " 2431,\n",
       " 2432,\n",
       " 2433,\n",
       " 2434,\n",
       " 2435,\n",
       " 2436,\n",
       " 2437,\n",
       " 2438,\n",
       " 2439,\n",
       " 2440,\n",
       " 2442,\n",
       " 2443,\n",
       " 2444,\n",
       " 2445,\n",
       " 2446,\n",
       " 2447,\n",
       " 2448,\n",
       " 2449,\n",
       " 2450,\n",
       " 2451,\n",
       " 2453,\n",
       " 2454,\n",
       " 2455,\n",
       " 2456,\n",
       " 2457,\n",
       " 2458,\n",
       " 2459,\n",
       " 2460,\n",
       " 2461,\n",
       " 2462,\n",
       " 2463,\n",
       " 2464,\n",
       " 2465,\n",
       " 2466,\n",
       " 2468,\n",
       " 2469,\n",
       " 2470,\n",
       " 2471,\n",
       " 2472,\n",
       " 2473,\n",
       " 2474,\n",
       " 2475,\n",
       " 2477,\n",
       " 2478,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_number = train_csv['Index'].tolist()\n",
    "pat_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cac9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch.transforms import ToTensorV2 # albumentations 텐서화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22d5eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1258: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n",
      "C:\\Users\\dhkim\\anaconda3\\lib\\site-packages\\albumentations\\augmentations\\transforms.py:1284: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(720,720),\n",
    "#     A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.Rotate(limit=30, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
    "#     A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
    "    A.RandomBrightness(limit=0.1, always_apply=False, p=0.5),\n",
    "    A.RandomContrast(limit=0.1, always_apply=False, p=0.5),\n",
    "#     A.Blur(blur_limit=7, always_apply=False, p=0.5),\n",
    "    \n",
    "    #     A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "#     A.ChannelShuffle(),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 이미지넷 데이터셋 통계값으로 Normalize\n",
    "#     A.CoarseDropout(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    A.Resize(720,720),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # 텐서타입은 안해줌\n",
    "    ToTensorV2() # Normalize를 먼저하고 tensor화를 진행해야한다.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "324a9ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dhkim\\\\Desktop\\\\directory\\\\k-ium\\\\data\\\\2023_k_ium_composition'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/shijianjian/EfficientNet-PyTorch-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e287f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_csv = pd.read_csv( 'C:/Users/dhkim/Desktop/directory/k-ium/data/2023_k_ium_composition/train_set/train.csv')\n",
    "# train_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "267f33ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhkim\\Desktop\\directory\\k-ium\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\dhkim\\\\Desktop\\\\directory\\\\k-ium\n",
    "\n",
    "root_path = 'C:/Users/dhkim/Desktop/directory/k-ium/data'\n",
    "\n",
    "from custom_8_3_h_w import Custom_dataset\n",
    "\n",
    "train_class = Custom_dataset(root_path=root_path, mode='train', transforms=train_transforms)\n",
    "valid_class = Custom_dataset(root_path=root_path, mode='val', transforms=test_transforms)\n",
    "test_class = Custom_dataset(root_path=root_path, mode='test', transforms=test_transforms)\n",
    "\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_loader = DataLoader(train_class, batch_size=batch_size, shuffle = True, num_workers=5)\n",
    "    valid_loader = DataLoader(valid_class, batch_size=batch_size, shuffle = False, num_workers=5)\n",
    "    test_loader = DataLoader(test_class, batch_size=batch_size, shuffle = False, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b62f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # 파이토치 뉴럴네트워크 layer 라이브러리\n",
    "import torchvision.models as models\n",
    "\n",
    "model_3d_resnet = models.video.r3d_18(pretrained=True).to(device)\n",
    "\n",
    "# model_3d_resnet.conv3 = nn.conv3d(3)\n",
    "\n",
    "model_3d_resnet.fc = nn.Linear(model_3d_resnet.fc.in_features, 2).to(device) #마지막의 fc 레이어를 바꿈\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5482a60b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1      [-1, 64, 8, 360, 360]          28,224\n",
      "       BatchNorm3d-2      [-1, 64, 8, 360, 360]             128\n",
      "              ReLU-3      [-1, 64, 8, 360, 360]               0\n",
      "      Conv3DSimple-4      [-1, 64, 8, 360, 360]         110,592\n",
      "       BatchNorm3d-5      [-1, 64, 8, 360, 360]             128\n",
      "              ReLU-6      [-1, 64, 8, 360, 360]               0\n",
      "      Conv3DSimple-7      [-1, 64, 8, 360, 360]         110,592\n",
      "       BatchNorm3d-8      [-1, 64, 8, 360, 360]             128\n",
      "              ReLU-9      [-1, 64, 8, 360, 360]               0\n",
      "       BasicBlock-10      [-1, 64, 8, 360, 360]               0\n",
      "     Conv3DSimple-11      [-1, 64, 8, 360, 360]         110,592\n",
      "      BatchNorm3d-12      [-1, 64, 8, 360, 360]             128\n",
      "             ReLU-13      [-1, 64, 8, 360, 360]               0\n",
      "     Conv3DSimple-14      [-1, 64, 8, 360, 360]         110,592\n",
      "      BatchNorm3d-15      [-1, 64, 8, 360, 360]             128\n",
      "             ReLU-16      [-1, 64, 8, 360, 360]               0\n",
      "       BasicBlock-17      [-1, 64, 8, 360, 360]               0\n",
      "     Conv3DSimple-18     [-1, 128, 4, 180, 180]         221,184\n",
      "      BatchNorm3d-19     [-1, 128, 4, 180, 180]             256\n",
      "             ReLU-20     [-1, 128, 4, 180, 180]               0\n",
      "     Conv3DSimple-21     [-1, 128, 4, 180, 180]         442,368\n",
      "      BatchNorm3d-22     [-1, 128, 4, 180, 180]             256\n",
      "           Conv3d-23     [-1, 128, 4, 180, 180]           8,192\n",
      "      BatchNorm3d-24     [-1, 128, 4, 180, 180]             256\n",
      "             ReLU-25     [-1, 128, 4, 180, 180]               0\n",
      "       BasicBlock-26     [-1, 128, 4, 180, 180]               0\n",
      "     Conv3DSimple-27     [-1, 128, 4, 180, 180]         442,368\n",
      "      BatchNorm3d-28     [-1, 128, 4, 180, 180]             256\n",
      "             ReLU-29     [-1, 128, 4, 180, 180]               0\n",
      "     Conv3DSimple-30     [-1, 128, 4, 180, 180]         442,368\n",
      "      BatchNorm3d-31     [-1, 128, 4, 180, 180]             256\n",
      "             ReLU-32     [-1, 128, 4, 180, 180]               0\n",
      "       BasicBlock-33     [-1, 128, 4, 180, 180]               0\n",
      "     Conv3DSimple-34       [-1, 256, 2, 90, 90]         884,736\n",
      "      BatchNorm3d-35       [-1, 256, 2, 90, 90]             512\n",
      "             ReLU-36       [-1, 256, 2, 90, 90]               0\n",
      "     Conv3DSimple-37       [-1, 256, 2, 90, 90]       1,769,472\n",
      "      BatchNorm3d-38       [-1, 256, 2, 90, 90]             512\n",
      "           Conv3d-39       [-1, 256, 2, 90, 90]          32,768\n",
      "      BatchNorm3d-40       [-1, 256, 2, 90, 90]             512\n",
      "             ReLU-41       [-1, 256, 2, 90, 90]               0\n",
      "       BasicBlock-42       [-1, 256, 2, 90, 90]               0\n",
      "     Conv3DSimple-43       [-1, 256, 2, 90, 90]       1,769,472\n",
      "      BatchNorm3d-44       [-1, 256, 2, 90, 90]             512\n",
      "             ReLU-45       [-1, 256, 2, 90, 90]               0\n",
      "     Conv3DSimple-46       [-1, 256, 2, 90, 90]       1,769,472\n",
      "      BatchNorm3d-47       [-1, 256, 2, 90, 90]             512\n",
      "             ReLU-48       [-1, 256, 2, 90, 90]               0\n",
      "       BasicBlock-49       [-1, 256, 2, 90, 90]               0\n",
      "     Conv3DSimple-50       [-1, 512, 1, 45, 45]       3,538,944\n",
      "      BatchNorm3d-51       [-1, 512, 1, 45, 45]           1,024\n",
      "             ReLU-52       [-1, 512, 1, 45, 45]               0\n",
      "     Conv3DSimple-53       [-1, 512, 1, 45, 45]       7,077,888\n",
      "      BatchNorm3d-54       [-1, 512, 1, 45, 45]           1,024\n",
      "           Conv3d-55       [-1, 512, 1, 45, 45]         131,072\n",
      "      BatchNorm3d-56       [-1, 512, 1, 45, 45]           1,024\n",
      "             ReLU-57       [-1, 512, 1, 45, 45]               0\n",
      "       BasicBlock-58       [-1, 512, 1, 45, 45]               0\n",
      "     Conv3DSimple-59       [-1, 512, 1, 45, 45]       7,077,888\n",
      "      BatchNorm3d-60       [-1, 512, 1, 45, 45]           1,024\n",
      "             ReLU-61       [-1, 512, 1, 45, 45]               0\n",
      "     Conv3DSimple-62       [-1, 512, 1, 45, 45]       7,077,888\n",
      "      BatchNorm3d-63       [-1, 512, 1, 45, 45]           1,024\n",
      "             ReLU-64       [-1, 512, 1, 45, 45]               0\n",
      "       BasicBlock-65       [-1, 512, 1, 45, 45]               0\n",
      "AdaptiveAvgPool3d-66         [-1, 512, 1, 1, 1]               0\n",
      "           Linear-67                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 33,167,298\n",
      "Trainable params: 33,167,298\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 47.46\n",
      "Forward/backward pass size (MB): 11264.07\n",
      "Params size (MB): 126.52\n",
      "Estimated Total Size (MB): 11438.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary # 모델 아키텍쳐 확인하는 함수\n",
    "\n",
    "summary(model_3d_resnet, input_size = (3,8, 720, 720))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26eb541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.000005\n",
    "\n",
    "optimizer = torch.optim.Adam(model_3d_resnet.parameters(), lr = lr, weight_decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebb02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [2:21:22, 282.68s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "criterion = nn.CrossEntropyLoss().to(device) # cost function\n",
    "\n",
    "train_acc_lst, train_loss_lst, test_acc_lst, test_loss_lst= [], [], [], []\n",
    "state={}\n",
    "train_auroc_lst= []\n",
    "test_auroc_lst = []\n",
    "y_pred = 0\n",
    "y_true = 0\n",
    "\n",
    "# 에포크 : training + evaluation\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "    \n",
    "#     # ----------------- TRAINING  -------------------- \n",
    "#     # training 모델로 설정\n",
    "    model_3d_resnet.train()\n",
    "    for i, (train_imgs, train_labels) in tqdm(enumerate(train_loader)):\n",
    "        # gpu에 할당\n",
    "            \n",
    "        train_img_permuted = train_imgs.permute(0, 2, 1, 3, 4)  # (32, 8, 3, 224, 224) -> (32, 3, 8, 224, 224)\n",
    "#         print(train_img_permuted.shape)\n",
    "        train_img = train_img_permuted.to(device)\n",
    "        train_label = train_labels.to(device)\n",
    "    \n",
    "        \n",
    "#         print(train_img.shape)\n",
    "        \n",
    "        output = model_3d_resnet(train_img) # 모델에 입력\n",
    "        optimizer.zero_grad(set_to_none = True ) # 계산했던 가중치 초기화               \n",
    "        loss = criterion(output, train_label)\n",
    "        loss.backward() # 미분\n",
    "        optimizer.step() # 학습\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predictions = torch.max(output.data ,dim = 1) \n",
    "\n",
    "        \n",
    "        y_true_train.append(train_label.cpu().numpy())# 추가 : 실제 레이블을 리스트에 추가\n",
    "        y_pred_train.append(predictions.cpu().numpy())# 추가 : 예측 확률을 리스트에 추가\n",
    "        \n",
    "#         print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "#         print(train_label.cpu().numpy())\n",
    "#         print(predictions.cpu().numpy())\n",
    "        \n",
    "        \n",
    "        total += train_label.size(0)\n",
    "        correct += (predictions == train_label).sum().item()\n",
    "        train_acc += 100 * (correct / total)\n",
    "    \n",
    "    train_loss = round(train_loss/(i+1), 3) # 소수점 반올림\n",
    "    train_acc = round(train_acc/(i+1), 3)\n",
    "    \n",
    "    \n",
    "    y_true_train = np.concatenate(y_true_train)  # 추가 : 저장된 실제 레이블 배열 결합\n",
    "    y_pred_train = np.concatenate(y_pred_train, axis=0)  # 추가 : 저장된 예측 확률 배열 결합\n",
    "    \n",
    "    auroc = roc_auc_score(y_true_train, y_pred_train)\n",
    "    print(f'Trainset {epoch}/{epochs} Loss : {train_loss}, Accuracy : {train_acc}%, AUROC : {auroc}')\n",
    "    train_acc_lst.append(train_acc)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    train_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "  # -------------------------------------------------------------------------------------\n",
    "    test_loss = 0.0\n",
    "    corrects = 0\n",
    "    totals = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    y_true_valid = []\n",
    "    y_pred_valid = []\n",
    "    \n",
    "#     print(\"~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    model_3d_resnet.eval()\n",
    "    for i, (valid_img, valid_label) in enumerate(valid_loader):\n",
    "        # gpu에 할당\n",
    "        \n",
    "        valid_img_permuted = valid_img.permute(0, 2, 1, 3, 4)  # (32, 8, 3, 224, 224) -> (32, 3, 8, 224, 224)\n",
    "#       \n",
    "        \n",
    "        valid_img = valid_img_permuted.to(device)\n",
    "        valid_label = valid_label.to(device)\n",
    "        \n",
    "        outputs = model_3d_resnet(valid_img) # 모델에 입력\n",
    "        losses = criterion(outputs, valid_label)\n",
    "        \n",
    "         # loss & acc\n",
    "        test_loss += losses.item()\n",
    "        _, predictions = torch.max(outputs.data ,dim = 1 )\n",
    "        \n",
    "#         print(\"@@@@@@@@@@@@@@@@@@\")\n",
    "#         print(len(valid_label))\n",
    "#         print(len(predictions))\n",
    "        y_true_valid.append(valid_label)# 추가 : 실제 레이블을 리스트에 추가\n",
    "        y_pred_valid.append(predictions)\n",
    "        \n",
    "#         valid_label = valid_label.to(device)\n",
    "        \n",
    "        totals += valid_label.size(0)\n",
    "        corrects += (predictions == valid_label).sum().item()\n",
    "        test_acc += 100 * (corrects / totals)\n",
    "    \n",
    "    test_loss = round(test_loss/(i+1), 3) # 소수점 반올림\n",
    "    test_acc = round(test_acc/(i+1), 3)\n",
    "    \n",
    "    \n",
    "#     print(\"~~\")\n",
    "#     print(len(y_true_valid))\n",
    "#     print(len(y_pred_valid))\n",
    "    \n",
    "#     print(y_true_valid)\n",
    "#     print(\"!!!!!!!!!!!!!!!!!!\")\n",
    "#     print(y_pred_valid)\n",
    "    \n",
    "    \n",
    "    y_true_valid = np.concatenate(y_true_valid)  # 추가 : 저장된 실제 레이블 배열 결합\n",
    "    y_pred_valid = np.concatenate(y_pred_valid)  # 추가 : 저장된 예측 확률 배열 결합\n",
    "    \n",
    "#     print(len(y_true_valid))\n",
    "#     print(len(y_pred_valid))\n",
    "    \n",
    "    auroc = roc_auc_score(y_true_valid, y_pred_valid)\n",
    "    print(f'Validset {epoch}/{epochs} Loss : {test_loss}, Accuracy : {test_acc}% \\n, AUROC : {auroc}')\n",
    "    test_loss_lst.append(test_loss)\n",
    "    test_acc_lst.append(test_acc)\n",
    "    test_auroc_lst.append(auroc)\n",
    "    \n",
    "    \n",
    "    if np.max(test_acc_lst) <= test_acc:\n",
    "        state['epoch'] = epoch\n",
    "        state['net'] = model_3d_resnet.state_dict()\n",
    "\n",
    "        state['train_loss'] = train_loss\n",
    "        state['test_loss'] = test_loss\n",
    "\n",
    "        state['train_acc'] = train_acc\n",
    "        state['test_acc'] = test_acc\n",
    "# torch.save(state, '/content/drive/MyDrive/Colab Notebooks/dna/week6/resnet50_{}_{}.pth'.format(str(state['epoch']), str(state['test_acc'])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e079b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  83, 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e9afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
